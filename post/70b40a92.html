<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 6.3.0">


  <link rel="apple-touch-icon" sizes="180x180" href="https://myblog-1258449291.cos.ap-beijing.myqcloud.com/wukong.jpg">
  <link rel="icon" type="image/png" sizes="32x32" href="https://myblog-1258449291.cos.ap-beijing.myqcloud.com/32_32_wukong.jpg">
  <link rel="icon" type="image/png" sizes="16x16" href="https://myblog-1258449291.cos.ap-beijing.myqcloud.com/16_16_wukong.jpg">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Serif+SC:300,300italic,400,400italic,700,700italic%7CRoboto+Slab:300,300italic,400,400italic,700,700italic%7CRoboto+Mono:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.css" integrity="sha256-Vzbj7sDDS/woiFS3uNKo8eIuni59rjyNGtXfstRzStA=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pace/1.2.4/themes/blue/pace-theme-minimal.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/pace/1.2.4/pace.min.js" integrity="sha256-gqd7YTjg/BtfqWSwsJOvndl0Bxc8gFImLEkXQT8+qj0=" crossorigin="anonymous"></script>

<script class="next-config" data-name="main" type="application/json">{"hostname":"oysz2016.github.io","root":"/","images":"/images","scheme":"Gemini","darkmode":false,"version":"8.9.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":true,"bookmark":{"enable":true,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":true,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":true,"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script>
<meta property="og:type" content="article">
<meta property="og:title" content="一篇文章搞懂Segment Anything(SAM)">
<meta property="og:url" content="https://oysz2016.github.io/post/70b40a92.html">
<meta property="og:site_name" content="冲弱&#39;s Blog">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://myblog-1258449291.cos.ap-beijing.myqcloud.com/Blog/SAM/5.png">
<meta property="article:published_time" content="2023-09-03T07:03:41.114Z">
<meta property="article:modified_time" content="2023-07-02T02:21:36.137Z">
<meta property="article:author" content="冲弱">
<meta property="article:tag" content="分割">
<meta property="article:tag" content="大模型">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://myblog-1258449291.cos.ap-beijing.myqcloud.com/Blog/SAM/5.png">


<link rel="canonical" href="https://oysz2016.github.io/post/70b40a92.html">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"https://oysz2016.github.io/post/70b40a92.html","path":"post/70b40a92.html","title":"一篇文章搞懂Segment Anything(SAM)"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>一篇文章搞懂Segment Anything(SAM) | 冲弱's Blog</title>
  




<link rel="dns-prefetch" href="waline-five-pi.vercel.app">
  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
<link rel="alternate" href="/atom.xml" title="冲弱's Blog" type="application/atom+xml">
<style>.darkmode--activated{--body-bg-color:#282828;--content-bg-color:#333;--card-bg-color:#555;--text-color:#ccc;--blockquote-color:#bbb;--link-color:#ccc;--link-hover-color:#eee;--brand-color:#ddd;--brand-hover-color:#ddd;--table-row-odd-bg-color:#282828;--table-row-hover-bg-color:#363636;--menu-item-bg-color:#555;--btn-default-bg:#222;--btn-default-color:#ccc;--btn-default-border-color:#555;--btn-default-hover-bg:#666;--btn-default-hover-color:#ccc;--btn-default-hover-border-color:#666;--highlight-background:#282b2e;--highlight-foreground:#a9b7c6;--highlight-gutter-background:#34393d;--highlight-gutter-foreground:#9ca9b6}.darkmode--activated img{opacity:.75}.darkmode--activated img:hover{opacity:.9}.darkmode--activated code{color:#69dbdc;background:0 0}button.darkmode-toggle{z-index:9999}.darkmode-ignore,img{display:flex!important}.beian img{display:inline-block!important}</style></head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">冲弱's Blog</p>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">多阅读 多积累</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu">
        <li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li>
        <li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li>
        <li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li>
        <li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li>
        <li class="menu-item menu-item-comment"><a href="/comment/" rel="section"><i class="fa fa-comment fa-fw"></i>评论</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#demo"><span class="nav-number">1.</span> <span class="nav-text">demo</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BB%BB%E5%8A%A1"><span class="nav-number">2.</span> <span class="nav-text">任务</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%A8%A1%E5%9E%8B"><span class="nav-number">3.</span> <span class="nav-text">模型</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE"><span class="nav-number">4.</span> <span class="nav-text">数据</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E5%BC%95%E6%93%8E"><span class="nav-number">4.1.</span> <span class="nav-text">数据引擎</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E8%B4%A8%E9%87%8F"><span class="nav-number">4.2.</span> <span class="nav-text">数据质量</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#zero-short-Transfer%E5%AE%9E%E9%AA%8C"><span class="nav-number">5.</span> <span class="nav-text">zero-short Transfer实验</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#point-mask"><span class="nav-number">5.1.</span> <span class="nav-text">point mask</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%BE%B9%E7%BC%98%E6%A3%80%E6%B5%8B"><span class="nav-number">5.2.</span> <span class="nav-text">边缘检测</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B"><span class="nav-number">5.3.</span> <span class="nav-text">目标检测</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AE%9E%E4%BE%8B%E5%88%86%E5%89%B2"><span class="nav-number">5.4.</span> <span class="nav-text">实例分割</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Text-to-Mask"><span class="nav-number">5.5.</span> <span class="nav-text">Text to Mask</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%B6%88%E8%9E%8D%E5%AE%9E%E9%AA%8C"><span class="nav-number">6.</span> <span class="nav-text">消融实验</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%80%BB%E7%BB%93"><span class="nav-number">7.</span> <span class="nav-text">总结</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="冲弱"
      src="https://myblog-1258449291.cos.ap-beijing.myqcloud.com/%E6%B4%BE%E5%A4%A7%E6%98%9F.png">
  <p class="site-author-name" itemprop="name">冲弱</p>
  <div class="site-description" itemprop="description">输出即获得，分享即反哺</div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">53</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">10</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">62</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author site-overview-item animated">
      <span class="links-of-author-item">
        <a href="/atom.xml" title="RSS → &#x2F;atom.xml"><i class="fa fa-rss fa-fw"></i>RSS</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:ouyang-sz@foxmail.com" title="E-Mail → mailto:ouyang-sz@foxmail.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://juejin.im/user/5ae26032f265da0b9f3ffeb2" title="掘金 → https:&#x2F;&#x2F;juejin.im&#x2F;user&#x2F;5ae26032f265da0b9f3ffeb2" rel="noopener" target="_blank"><i class="fa fa-spinner fa-fw"></i>掘金</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://www.zhihu.com/people/ou-yang-shi-zhuang/activities" title="知乎 → https:&#x2F;&#x2F;www.zhihu.com&#x2F;people&#x2F;ou-yang-shi-zhuang&#x2F;activities" rel="noopener" target="_blank"><i class="fab fa-zhihu fa-fw"></i>知乎</a>
      </span>
  </div>



        </div>
      </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>
  <a role="button" class="book-mark-link book-mark-link-fixed"></a>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  <div class="post-gallery" itemscope itemtype="http://schema.org/ImageGallery">
    
    <div class="post-gallery-image">
      <img src="https://myblog-1258449291.cos.ap-beijing.myqcloud.com/Blog/SAM/5.png" itemprop="contentUrl">
    </div>
    </div>

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://oysz2016.github.io/post/70b40a92.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://myblog-1258449291.cos.ap-beijing.myqcloud.com/%E6%B4%BE%E5%A4%A7%E6%98%9F.png">
      <meta itemprop="name" content="冲弱">
      <meta itemprop="description" content="输出即获得，分享即反哺">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="冲弱's Blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          一篇文章搞懂Segment Anything(SAM)
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2023-09-03 15:03:41" itemprop="dateCreated datePublished" datetime="2023-09-03T15:03:41+08:00">2023-09-03</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2023-07-02 10:21:36" itemprop="dateModified" datetime="2023-07-02T10:21:36+08:00">2023-07-02</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">深度学习</span></a>
        </span>
    </span>

  
    <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">阅读次数：</span>
      <span id="busuanzi_value_page_pv"></span>
    </span>
  
  <span class="post-meta-item">
    
    <span class="post-meta-item-icon">
      <i class="far fa-comment"></i>
    </span>
    <span class="post-meta-item-text">Waline：</span>
  
    <a title="waline" href="/post/70b40a92.html#waline" itemprop="discussionUrl">
      <span class="post-comments-count waline-comment-count" data-path="/post/70b40a92.html" itemprop="commentCount"></span>
    </a>
  </span>
  
  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>5.6k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>5 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <p><p class="description"></p><br><span id="more"></span></p>
<p>本文首发于公众号“<a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s?__biz=MzU4NjU4MDY1OA==&amp;mid=2247484634&amp;idx=1&amp;sn=b102b609e965dd916e00042f12c9a2fb&amp;chksm=fdf85307ca8fda1126191dc4ed7452a03c418bc6f1c43a45cf984b722aa07321281503264fe0&amp;scene=178&amp;cur_album_id=2977728123201126402#rd">CVTALK</a>”。</p>
<p><strong>论文链接:</strong><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2304.02643">https://arxiv.org/abs/2304.02643</a></p>
<p><strong>代码链接:</strong><a target="_blank" rel="noopener" href="https://github.com/lllyasviel/ControlNet">https://github.com/lllyasviel/ControlNet</a></p>
<p><strong>Demo链接:</strong><a target="_blank" rel="noopener" href="https://segment-anything.com/demo">https://segment-anything.com/demo</a></p>
<p>SAM从任务、模型、数据三部分展开写作，和模型的创新比较起来，任务定义和数据的工作更加出彩，官网也给出了demo，能直观感受SAM的效果，这篇blog也会围绕这几部分展开。</p>
<h2 id="demo"><a href="#demo" class="headerlink" title="demo"></a>demo</h2><p>demo中有开放point, box, everything三种方式。由于text prompt效果不太稳定，demo和代码中都没有该部分。</p>
<ul>
<li><strong>鼠标悬停:</strong> 显示的是悬停位置的分割结果，例如下图中将鼠标放到手的位置.<br><img data-src="https://myblog-1258449291.cos.ap-beijing.myqcloud.com/Blog/SAM/1.png" alt=""></li>
</ul>
<ul>
<li><strong>点击:</strong> 分割包含该点的物体，会按最小分割的结果展示出来，如果想分割的物体大于展示的结果，可以在物体的其他部分也点击下。</li>
</ul>
<p><img data-src="https://myblog-1258449291.cos.ap-beijing.myqcloud.com/Blog/SAM/2.png" alt=""></p>
<p><img data-src="https://myblog-1258449291.cos.ap-beijing.myqcloud.com/Blog/SAM/3.png" alt=""></p>
<ul>
<li><strong>box:</strong> 框定一个box，分割box中的物体<br><img data-src="https://myblog-1258449291.cos.ap-beijing.myqcloud.com/Blog/SAM/4.png" alt=""></li>
</ul>
<ul>
<li><strong>everything:</strong> 将图片中所有物体的分割都展示出来<br><img data-src="https://myblog-1258449291.cos.ap-beijing.myqcloud.com/Blog/SAM/5.png" alt=""></li>
</ul>
<h2 id="任务"><a href="#任务" class="headerlink" title="任务"></a>任务</h2><p><img data-src="https://myblog-1258449291.cos.ap-beijing.myqcloud.com/Blog/SAM/6.png" alt=""></p>
<p>任务的设计灵感来自于NLP领域，例如NLP中可以通过预测next token作为预训练任务，而在下游任务中可以使用prompt engineering做应用。因此，为了建立分割的基础模型，任务的设计目标是也需要具有类似的能力。<br>这里作者扩展了下NLP里prompt在图像分割里的用法， prompt可以是以下几种类型：</p>
<ul>
<li>point</li>
<li>box</li>
<li>mask</li>
<li>任意格式的文本</li>
</ul>
<p>为了支持以下的几种输入prompt格式，要求模型能够区分具有混淆意义的prompt，例如下图中，一个point的prompt可能有多种分割方式.这多种分割方式对于模型来说都是有效的。<br><img data-src="https://myblog-1258449291.cos.ap-beijing.myqcloud.com/Blog/SAM/7.png" alt=""></p>
<p>预训练:  将上面提到的多种sequence的prompt告诉模型，训练目标是让模型输出对应promt的分割结果，并且期望模型输出的结果和GT尽可能一致。区别于之前的交互式分割算法，SAM基本能治通过一次交互就能得到很合理的分割结果。要达到这个目的，需要设计非常独特的模型结构和loss。</p>
<p>zero-shot transfer：需要模型对任何prompt，得到合适的分割结果。例如，如果要做实例分割，可以把检测得到的box作为prompt，SAM就能去做实例分割</p>
<p>related tasks: 分割里有很多子任务，例如边缘分割，语义分割等，SAM能完成所有已知的分割任务和还没有作为一个方向的分割任务。之前已经有类似的可以做多种分割的模型(solo), 但是这些模型有多个子子输出，然后做排列组合可以得到多种分割结果。而SAM通过prompt将多个分割任务合并在一起。</p>
<p>总而言之，作者是希望SAM能够分割一切，并且能相CLIP一样，能应用到最开始没有想到的领域。</p>
<h2 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h2><p><img data-src="https://myblog-1258449291.cos.ap-beijing.myqcloud.com/Blog/SAM/8.png" alt=""></p>
<p><img data-src="https://myblog-1258449291.cos.ap-beijing.myqcloud.com/Blog/SAM/9.png" alt=""></p>
<p>模型的结构如上图所示. prompt会经过<code>prompt encoder</code>, 图像会经过<code>image encoder</code>。然后将两部分embedding经过一个轻量化的<code>mask decoder</code>得到融合后的特征。encoder部分使用的都是已有模型，decoder使用transformer。这部分论文中介绍的相对比较少，下面会结合代码一起梳理下:</p>
<ul>
<li><p><strong>image encoder：</strong> 使用的是用ViT走位backbone的MAE模型。在交互式分割的展示中，image encoder只会运行一次。在实验中，分别有用到ViT-H, ViT-L, ViT-B三种大小的模型作为image encoder。代码如下,<a target="_blank" rel="noopener" href="https://github.com/facebookresearch/segment-anything/blob/6fdee8f2727f4506cfbbe553e23b895e27956588/segment_anything/build_sam.py#L47">build_sam#L47</a> </p>
<figure class="highlight mipsasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">sam_model_registry = &#123;</span><br><span class="line">    <span class="string">&quot;default&quot;</span>: <span class="keyword">build_sam_vit_h,</span></span><br><span class="line"><span class="keyword"></span>    <span class="string">&quot;vit_h&quot;</span>: <span class="keyword">build_sam_vit_h,</span></span><br><span class="line"><span class="keyword"></span>    <span class="string">&quot;vit_l&quot;</span>: <span class="keyword">build_sam_vit_l,</span></span><br><span class="line"><span class="keyword"></span>    <span class="string">&quot;vit_b&quot;</span>: <span class="keyword">build_sam_vit_b,</span></span><br><span class="line"><span class="keyword"></span>&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>prompt encoder：</strong> prompt总共有point,box, mask, text四种，会将其分为三类。<strong>pint和box可以作为一类使用position encodings</strong>, <strong>text可以使用CLIP作为encoder</strong>, <strong>而mask是一种密集型的prompt，可以使用卷积作为encoder</strong>.<a target="_blank" rel="noopener" href="https://github.com/facebookresearch/segment-anything/blob/6fdee8f2727f4506cfbbe553e23b895e27956588/segment_anything/modeling/prompt_encoder.py#LL128C5-L128C5">prompt_encoder.py#LL128C5-L128C5</a> prompt_encoder的代码如下所示，其中用position embedding分别实现了point和box query两种稀疏embedding，用卷积实现了mask query密集embedding.，</p>
<figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">def forward(</span><br><span class="line">        self,</span><br><span class="line">        points: Optional[Tuple[torch.Tensor, torch.Tensor]],</span><br><span class="line">        boxes: Optional[torch.Tensor],</span><br><span class="line">        masks: Optional[torch.Tensor],</span><br><span class="line">    ) -&gt; Tuple[torch.Tensor, torch.Tensor]:</span><br><span class="line">        <span class="string">&quot;&quot;</span><span class="comment">&quot;</span></span><br><span class="line">        Embeds different types of prompts, returning both sparse <span class="built_in">and</span> dense</span><br><span class="line">        embeddings.</span><br><span class="line"></span><br><span class="line">        Arguments:</span><br><span class="line">          points (tuple(torch.Tensor, torch.Tensor) <span class="built_in">or</span> none): point coordinates</span><br><span class="line">            <span class="built_in">and</span> labels <span class="keyword">to</span> embed.</span><br><span class="line">          boxes (torch.Tensor <span class="built_in">or</span> none): boxes <span class="keyword">to</span> embed</span><br><span class="line">          masks (torch.Tensor <span class="built_in">or</span> none): masks <span class="keyword">to</span> embed</span><br><span class="line"></span><br><span class="line">        Returns:</span><br><span class="line">          torch.Tensor: sparse embeddings <span class="keyword">for</span> the points <span class="built_in">and</span> boxes, with shape</span><br><span class="line">            BxNx(embed_dim), where <span class="keyword">N</span> <span class="keyword">is</span> determined by the <span class="keyword">number</span> of <span class="built_in">input</span> points</span><br><span class="line">            <span class="built_in">and</span> boxes.</span><br><span class="line">          torch.Tensor: dense embeddings <span class="keyword">for</span> the masks, in the shape</span><br><span class="line">            Bx(embed_dim)<span class="keyword">x</span>(embed_H)<span class="keyword">x</span>(embed_W)</span><br><span class="line">        <span class="string">&quot;&quot;</span><span class="comment">&quot;</span></span><br><span class="line">        bs = self._get_batch_size(points, boxes, masks)</span><br><span class="line">        sparse_embeddings = torch.<span class="built_in">empty</span>((bs, <span class="number">0</span>, self.embed_dim), device=self._get_device())</span><br><span class="line">        <span class="keyword">if</span> points <span class="keyword">is</span> not None:</span><br><span class="line">            coords, labels = points</span><br><span class="line">            point_embeddings = self._embed_points(coords, labels, pad=(boxes <span class="keyword">is</span> None))     # position embedding</span><br><span class="line">            sparse_embeddings = torch.<span class="keyword">cat</span>([sparse_embeddings, point_embeddings], dim=<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">if</span> boxes <span class="keyword">is</span> not None:</span><br><span class="line">            box_embeddings = self._embed_boxes(boxes)   # position embedding</span><br><span class="line">            sparse_embeddings = torch.<span class="keyword">cat</span>([sparse_embeddings, box_embeddings], dim=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> masks <span class="keyword">is</span> not None:</span><br><span class="line">            dense_embeddings = self._embed_masks(masks)    # conv embedding</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            dense_embeddings = self.no_mask_embed.weight.reshape(<span class="number">1</span>, -<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>).<span class="built_in">expand</span>(</span><br><span class="line">                bs, -<span class="number">1</span>, self.image_embedding_size[<span class="number">0</span>], self.image_embedding_size[<span class="number">1</span>]</span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> sparse_embeddings, dense_embeddings</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>mask decoder：</strong>: 使用一个transformer将image embedding和prompt embedding做双向的cross-attention；并且也有prompt embedding的self-attention。也有MLP和linear classifier分类分割区域。mask decoder, <a target="_blank" rel="noopener" href="https://github.com/facebookresearch/segment-anything/blob/6fdee8f2727f4506cfbbe553e23b895e27956588/segment_anything/modeling/transformer.py#L151">transformer.py#L151</a>这里的queries是query embedding，keys是image embedding，query_pe和queries一样，key_pe是需要加到image embedding上的位置编码。query embedding会经过self attention。query embedding和image embedding会做双向的cross-attention, 具体实现方式是如上代码所示，image embedding会作为query，query embedding会作为key和value；同样的，query embedding会作为query，image embedding会作为key和value。</p>
<figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line">def forward(</span><br><span class="line">        self,</span><br><span class="line">        image_embedding: Tensor,</span><br><span class="line">        image_pe: Tensor,</span><br><span class="line">        point_embedding: Tensor,</span><br><span class="line">    ) -&gt; Tuple[Tensor, Tensor]:</span><br><span class="line">        <span class="string">&quot;&quot;</span><span class="comment">&quot;</span></span><br><span class="line">        Args:</span><br><span class="line">          image_embedding (torch.Tensor): image <span class="keyword">to</span> attend <span class="keyword">to</span>. Should <span class="keyword">be</span> shape</span><br><span class="line">            B <span class="keyword">x</span> embedding_dim <span class="keyword">x</span> h <span class="keyword">x</span> <span class="keyword">w</span> <span class="keyword">for</span> any h <span class="built_in">and</span> <span class="keyword">w</span>.</span><br><span class="line">          image_pe (torch.Tensor): the positional encoding <span class="keyword">to</span> <span class="built_in">add</span> <span class="keyword">to</span> the image. Must</span><br><span class="line">            have the same shape <span class="keyword">as</span> image_embedding.</span><br><span class="line">          point_embedding (torch.Tensor): the embedding <span class="keyword">to</span> <span class="built_in">add</span> <span class="keyword">to</span> the query points.</span><br><span class="line">            Must have shape B <span class="keyword">x</span> N_points <span class="keyword">x</span> embedding_dim <span class="keyword">for</span> any N_points.</span><br><span class="line"></span><br><span class="line">        Returns:</span><br><span class="line">          torch.Tensor: the processed point_embedding</span><br><span class="line">          torch.Tensor: the processed image_embedding</span><br><span class="line">        <span class="string">&quot;&quot;</span><span class="comment">&quot;</span></span><br><span class="line">        # BxCxHxW -&gt; BxHWxC == B <span class="keyword">x</span> N_image_tokens <span class="keyword">x</span> C</span><br><span class="line">        bs, <span class="keyword">c</span>, h, <span class="keyword">w</span> = image_embedding.shape</span><br><span class="line">        image_embedding = image_embedding.flatten(<span class="number">2</span>).permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">        image_pe = image_pe.flatten(<span class="number">2</span>).permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        # Prepare queries</span><br><span class="line">        queries = point_embedding</span><br><span class="line">        <span class="built_in">keys</span> = image_embedding</span><br><span class="line"></span><br><span class="line">        # Apply transformer blocks <span class="built_in">and</span> final layernorm</span><br><span class="line">        <span class="keyword">for</span> layer in self.layers:</span><br><span class="line">            queries, <span class="built_in">keys</span> = layer(</span><br><span class="line">                queries=queries,</span><br><span class="line">                <span class="built_in">keys</span>=<span class="built_in">keys</span>,</span><br><span class="line">                query_pe=point_embedding,</span><br><span class="line">                key_pe=image_pe,</span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">        # Apply the final attention layer from the points <span class="keyword">to</span> the image</span><br><span class="line">        q = queries + point_embedding</span><br><span class="line">        <span class="keyword">k</span> = <span class="built_in">keys</span> + image_pe</span><br><span class="line">        attn_out = self.final_attn_token_to_image(q=q, <span class="keyword">k</span>=<span class="keyword">k</span>, v=<span class="built_in">keys</span>)</span><br><span class="line">        queries = queries + attn_out</span><br><span class="line">        queries = self.norm_final_attn(queries)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> queries, <span class="built_in">keys</span></span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>解决混淆的输入</strong>: 对于一个prompt，模型会输出3个mask，实际上也可以输出更多的分割结果，3个可以看作一个物体的整体、部分、子部分，基本能满足大多数情况。使用IOU的方式，排序mask。在反向传播时，参与计算的只有loss最小的mask相关的参数.</p>
</li>
<li><p><strong>高效</strong>: 这里主要指的是<strong>prompt encoder</strong>和<strong>mask decoder</strong>。在web浏览器上，CPU计算只用约50ms</p>
</li>
<li><p><strong>loss和训练细节</strong>: 主要使用的是focal loss和dice loss。每一个mask，会随机产生11种prompt与之配对。</p>
</li>
</ul>
<h2 id="数据"><a href="#数据" class="headerlink" title="数据"></a>数据</h2><h3 id="数据引擎"><a href="#数据引擎" class="headerlink" title="数据引擎"></a>数据引擎</h3><p>不像CLIP中图像文本对通过互联网容易获取，分割的数据获取成本巨大。SAM开源了一个10亿张图片的分割数据集。在SAM中设计了一个数据引擎用于获取分割的数据，数据引擎主要分为以下三部分:</p>
<ul>
<li><p>辅助标注: 简单来说就是用可以获取到的开源分割数据训练一个初始的SAM模型V0版本，再用V0在没有分割标注的数据上生成预标注，人工check模型的结果并作修改和确认。得到新的数据后，再将新的数据加入到训练集重新训练SAM得到V1版本,再循环标注数据和迭代模型。总共进行6次训练。开始的时候数据集比较少，使用的ViT-B模型，最终会使用ViT-H模型。 这里面还有一些效率提升的数据，例如随着模型的迭代，每个mask的标注耗时从34s到14s。SAM模型在每张图片上生成的mask从20到44个。在该阶段数据集最终有12万张图片，430万个mask</p>
</li>
<li><p>半自动化标注: 通过第一阶段后，已经有一个不错的SAM模型能生成分割结果。<strong>半自动化标注</strong>的目的是增加mask的多样性。具体做法是训练一个检测模型，用于检测SAM生成的mask结果是否可信，只保留可信的mask结果，然后将图片给人工标注。人工标注会在可信的mask基础上标注出其他的分割框。经过5次的迭代后，数据集新增了18万张图片，590万mask。</p>
</li>
</ul>
<p><strong>自动标注</strong>: 经过前面两个阶段后，SAM有了较好的结果，能分割出图片中的目标，并且对于混淆的prompt也有了较好的输出。这个模型可以自动的对一些图片做标注。自动标注的时候需要有一些筛选策略，模型输出的结果可能还是会出现一些错误。主要有以下三种方式做筛选</p>
<ul>
<li>SAM模型有一个IOU prediction的模块能输出mask的confidence，如下图所示<br><img data-src="https://myblog-1258449291.cos.ap-beijing.myqcloud.com/Blog/SAM/10.png" alt=""></li>
</ul>
<ul>
<li><p>stable mask的判断，具体的方法是在得到分割结果前对logit加正向和负向的扰动，如果两次扰动生成的分割结果IOU大于0.95，则认为生成的mask是可靠的</p>
</li>
<li><p>NMS过滤掉重复的mask</p>
</li>
</ul>
<p><img data-src="https://myblog-1258449291.cos.ap-beijing.myqcloud.com/Blog/SAM/11.png" alt=""></p>
<h3 id="数据质量"><a href="#数据质量" class="headerlink" title="数据质量"></a>数据质量</h3><p> 图像: 包含11M高分辨率(3300<em>4950)的图像，其他的一些开源数据集，例如COCO分辨率较低(480</em>640)<br>Mask: 包含1.1B的mask，99.1%都是模型生成的。作者实验了下，只使用模型生成的mask和即使用模型生成也使用人工标注的mask，模型的效果是相当的。因此发布的数据集里只包含模型生成的mask<br>Mask 质量: 抽取了一部分mask数据做人工的精标，精标前后有94%的mask具有90%以上的IOU。而其他的一些开源数据集只有85-91%的IOU</p>
<p>下面也从mask的数量，每种mask尺寸的占比和mask占外接矩形比例等多方面和其他数据集做了对比<br><img data-src="https://myblog-1258449291.cos.ap-beijing.myqcloud.com/Blog/SAM/12.png" alt=""></p>
<p>数据来源分布<br><img data-src="https://myblog-1258449291.cos.ap-beijing.myqcloud.com/Blog/SAM/13.png" alt=""></p>
<p><img data-src="https://myblog-1258449291.cos.ap-beijing.myqcloud.com/Blog/SAM/14.png" alt=""></p>
<p>不同性别，肤色，年龄人群分割效果的差异对比<br><img data-src="https://myblog-1258449291.cos.ap-beijing.myqcloud.com/Blog/SAM/15.png" alt=""></p>
<h2 id="zero-short-Transfer实验"><a href="#zero-short-Transfer实验" class="headerlink" title="zero-short Transfer实验"></a>zero-short Transfer实验</h2><p>评估的数据集都是SAM模型训练时的不同，并且包含水下，第一视角等没有在SAM中出现过场景的图片</p>
<h3 id="point-mask"><a href="#point-mask" class="headerlink" title="point mask"></a>point mask</h3><p>这里对比的是用point作为prompt对比分割的结果, 在绝大部分数据集中都优于RITM(当前的SOTA) </p>
<p><img data-src="https://myblog-1258449291.cos.ap-beijing.myqcloud.com/Blog/SAM/16.png" alt=""></p>
<h3 id="边缘检测"><a href="#边缘检测" class="headerlink" title="边缘检测"></a>边缘检测</h3><p>SAM在训练的时候就是采用的包含point prompt的方式，作者这里还对比了一些在训练时没有包含的方式，边界检测就是其中一种。SAM在使用边界检测时，使用方式是在图片上铺上16*16均匀的point prompt，每个prompt产生3个mask，再经过NMS后。通过Sobel filtering得到边缘检测的结果。SAM的结果倾向于提取更丰富的边缘，因此在指标上recall和专门做边缘检测的模型相当，precision会低些。</p>
<p><img data-src="https://myblog-1258449291.cos.ap-beijing.myqcloud.com/Blog/SAM/17.png" alt=""></p>
<p><img data-src="https://myblog-1258449291.cos.ap-beijing.myqcloud.com/Blog/SAM/18.png" alt=""></p>
<h3 id="目标检测"><a href="#目标检测" class="headerlink" title="目标检测"></a>目标检测</h3><p>分割的结果取bbox，就能做目标检测了.整体指标低于ViTDet，但是在中等常见和不太常见的目标上效果优于ViTDet</p>
<p><img data-src="https://myblog-1258449291.cos.ap-beijing.myqcloud.com/Blog/SAM/19.png" alt=""></p>
<h3 id="实例分割"><a href="#实例分割" class="headerlink" title="实例分割"></a>实例分割</h3><p>先用一个目标检测算法，用目标检测得到的box作为prompt输入到SAM，就可以做实例分割了。实验的结果分为了定量(用测试集的GT)和定性(人来评判好坏)两种。定量的指标不如BiTDet—H,定性的指标SAM优于ViTDet。作者给出的解释是COCO数据集标注效果一般(在人看来甚至不如SAM和ViTDet模型输出的结果)，因此ViTDet在COCO上做训练时拟合到了一些错误的偏差，但错误的偏差和标注相似，因此定量的指标不如ViTDet</p>
<p><img data-src="https://myblog-1258449291.cos.ap-beijing.myqcloud.com/Blog/SAM/20.png" alt=""></p>
<p><img data-src="https://myblog-1258449291.cos.ap-beijing.myqcloud.com/Blog/SAM/21.png" alt=""></p>
<h3 id="Text-to-Mask"><a href="#Text-to-Mask" class="headerlink" title="Text to Mask"></a>Text to Mask</h3><p>这里指的是用文本作为prompt，然后分割出文本提到的目标。作者在训练的时候取的是图片中目标尺寸大于100*100的目标，用CLIP提取image embedding(text embedding也行，因为CLIP的image embedding和text embedding是对齐的)，作为prompt encoder模块的输出，用于训练SAM模型。这一部分没有和其他方法对比，也由于效果不太稳定，在官方的demo中没有展示</p>
<p><img data-src="https://myblog-1258449291.cos.ap-beijing.myqcloud.com/Blog/SAM/22.png" alt=""></p>
<h2 id="消融实验"><a href="#消融实验" class="headerlink" title="消融实验"></a>消融实验</h2><p><img data-src="https://myblog-1258449291.cos.ap-beijing.myqcloud.com/Blog/SAM/23.png" alt=""></p>
<p>有以下的结论:<br>左边的图，数据来源的影响:</p>
<ul>
<li>加入半自动标注的数据和自动标注的数据性能都有很大的提升</li>
<li>只用模型生成的数据与额外加上人工标注的数据差异不大</li>
</ul>
<p>中间的图, 数据量的影响:</p>
<ul>
<li>数据量从0.1M到1M，模型性能提升很大</li>
<li>数据量从1M到11M，模型性能变化不明显，实际使用中1M差不多足够</li>
</ul>
<p>右边的图, image encoder的影响:</p>
<ul>
<li>ViT-B到ViT-L提升很大</li>
<li>ViT-L到ViT-H提升一般，实际使用ViT-L足够</li>
</ul>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>SAM的热度也非常高，同样作为FB的工作，SAM仅仅放出来两个月，github上star的数量已经超过了detectron2三年的总和。SAM的期望是能将该模型作为图像领域的基础模型(foundation model)，像CLIP那样能在各个领域大放异常，或者像GPT一样能统一NLP领域。SAM也确实在很多场景得到了应用，例如开源的SD中也融合了SAM，可以做很多有趣的应用，例如从假人模特身上用SAM得到衣服的mask，再结合ControlNet，就可以生成不同的人穿着同样的衣服。</p>
<p>最开始自媒体宣传的文章也是《CV领域不存在了》,《CV界的GPT3》类似的标题，SAM确实是在统一上迈出了很大的一步，但实际上CV领域的统一还有很多挑战。NLP领域中的Bert用完型填空和GPT预测下一个token的预训练在非常多的任务上表现了很好的泛化性，甚至在一些没有训练过的任务上能取得比一些专家模型更好的效果。</p>
<ul>
<li><p>任务和数据上的不统一，CV领域的分类是输出类别，检测输出bbox，分割输出mask。虽然个别任务可以复用，但是整体缺乏一个通用的任务。任务上的不统一，数据上也很难做到统一，分类的任务有很多数据，但是检测和分割的数据就要少非常多，并且标注成本巨大。单纯训练分类作为backbone也很难解决其他任务，检测和分割的算法依然需要做大量的优化</p>
</li>
<li><p>CV领域的任务缺乏孕育大模型的土壤，CV任务一直在考虑模型的计算量，显存占用。如果将每个像素看作一个token，一张512*512的图片就有26万个token。如果transformer最开始出现在CV领域，面临的问题是显存和计算量都比resnet差，并且效果也远不如resnet。如果没有transformer极大的促进了NLP领域的发展，CV领域可能也不会重新思考transfomer能增大感受野，能有更好的泛化能力。</p>
</li>
<li><p>还没有找到CV领域【高维】的任务。NLP领域的完形填空和对话确实是一种很高维的任务。模型能完成这些任务，一些NER或者RE之类的底层任务也能很好的被解决。目前CV领域有一些尝试做foundation model，例如对比学习或者像SAM，在一些任务上表现了不错的泛化性，可能是这些方法能统一其他任务，但目前的发展还不太够，也可能是其他一些还没出现/发展起来的任务。但这种【高维】的任务一定能通过一些方式降维解决目前几乎所有的CV基础任务。</p>
</li>
</ul>

    </div>

    
    
    

    <div>
      
        <div>
    
        <div style="text-align:center;color: #ccc;font-size:14px;">-------------本文结束<i class="fa fa-paw"></i>感谢您的阅读-------------</div>
    
</div>

      
    </div>

    <footer class="post-footer">
          <div class="reward-container">
  <div>坚持原创技术分享，您的支持将鼓励我继续创作！</div>
  <button>
    赞赏
  </button>
  <div class="post-reward">
      <div>
        <img src="https://myblog-1258449291.cos.ap-beijing.myqcloud.com/wechatpay.jpg" alt="冲弱 微信">
        <span>微信</span>
      </div>
      <div>
        <img src="https://myblog-1258449291.cos.ap-beijing.myqcloud.com/alipay.jpg" alt="冲弱 支付宝">
        <span>支付宝</span>
      </div>

  </div>
</div>

          

<div class="post-copyright">
<ul>
  <li class="post-copyright-author">
      <strong>原作者： </strong>冲弱
  </li>
  <li class="post-copyright-link">
      <strong>本文链接：</strong>
      <a href="https://oysz2016.github.io/post/70b40a92.html" title="一篇文章搞懂Segment Anything(SAM)">https://oysz2016.github.io/post/70b40a92.html</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！
  </li>
</ul>
</div>

          <div class="followme">
  <span>欢迎关注我的其它发布渠道</span>

  <div class="social-list">

      <div class="social-item">
        <a target="_blank" class="social-link" href="https://myblog-1258449291.cos.ap-beijing.myqcloud.com/%E5%85%AC%E4%BC%97%E5%8F%B7.jpg">
          <span class="icon">
            <i class="fab fa-weixin"></i>
          </span>

          <span class="label">WeChat</span>
        </a>
      </div>

      <div class="social-item">
        <a target="_blank" class="social-link" href="https://www.zhihu.com/people/ou-yang-shi-zhuang/posts">
          <span class="icon">
            <i class="fab fa-zhihu"></i>
          </span>

          <span class="label">ZhiHu</span>
        </a>
      </div>

      <div class="social-item">
        <a target="_blank" class="social-link" href="https://juejin.cn/user/4353721775688920">
          <span class="icon">
            <i class="fa fa-spinner"></i>
          </span>

          <span class="label">JueJin</span>
        </a>
      </div>
  </div>
</div>

          <div class="post-tags">
              <a href="/tags/%E5%88%86%E5%89%B2/" rel="tag"> <i class="fa fa-tag"></i> 分割</a>
              <a href="/tags/%E5%A4%A7%E6%A8%A1%E5%9E%8B/" rel="tag"> <i class="fa fa-tag"></i> 大模型</a>
          </div>

        
  <div class="post-widgets">
    <div class="wpac-rating-container">
      <div id="wpac-rating"></div>
    </div>
  </div>

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/post/e2effb33.html" rel="prev" title="一篇文章搞懂iBOT">
                  <i class="fa fa-chevron-left"></i> 一篇文章搞懂iBOT
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/post/309a28b1.html" rel="next" title="什么是深度学习">
                  什么是深度学习 <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






    <div class="comments" id="waline"></div>
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2024</span>
  <span class="with-love">
    <i class="user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">冲弱</span>
</div>
<div class="wordcount">
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-line"></i>站点总字数:
    </span>
    <span title="站点总字数">169k</span>
  </span>
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>站点阅读时长:
    </span>
    <span title="站点阅读时长">2:34</span>
  </span>
</div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>
  <div class="addthis_inline_share_toolbox">
    <script src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5adaebc9009ff58b" async="async"></script>
  </div>
  <div id="site-runtime">
  <span class="post-meta-item-icon">
    <i class="fa fa-clock-o"></i>
  </span>
  <span id="runtime"></span>
</div>

<script language="javascript">
  function isPC() {
    var userAgentInfo = navigator.userAgent;
    var agents = ["Android", "iPhone", "SymbianOS", "Windows Phone", "iPad", "iPod"];
    for (var i = 0; i < agents.length; i++) {
      if (userAgentInfo.indexOf(agents[i]) > 0) {
        return false;
      }
    }
    return true;
  }

  function siteTime(openOnPC, start) {
    window.setTimeout("siteTime(openOnPC, start)", 1000);
    var seconds = 1000;
    var minutes = seconds * 60;
    var hours = minutes * 60;
    var days = hours * 24;
    var years = days * 365;
      start = new Date("2018-04-23 09:00:00 +0800");
    var now = new Date();
    var year = now.getFullYear();
    var month = now.getMonth() + 1;
    var date = now.getDate();
    var hour = now.getHours();
    var minute = now.getMinutes();
    var second = now.getSeconds();
    var diff = now - start;

    var diffYears = Math.floor(diff / years);
    var diffDays = Math.floor((diff / days) - diffYears * 365);
    var diffHours = Math.floor((diff - (diffYears * 365 + diffDays) * days) / hours);
    var diffMinutes = Math.floor((diff - (diffYears * 365 + diffDays) * days - diffHours * hours) / minutes);
    var diffSeconds = Math.floor((diff - (diffYears * 365 + diffDays) * days - diffHours * hours - diffMinutes * minutes) / seconds);

    if (openOnPC) {
      document.getElementById("runtime").innerHTML = "Running: " + diffYears + " years " + diffDays + " days " + diffHours + " hours " + diffMinutes + " mins " + diffSeconds + " secs";
    } else {
      document.getElementById("runtime").innerHTML = "Running: " + diffYears + "y " + diffDays + "d " + diffHours + "h " + diffMinutes + "m " + diffSeconds + "s";
    }
  }

  var showOnMobile = true;
  var openOnPC = isPC();
  var start = new Date();
  siteTime(openOnPC, start);

  if (!openOnPC && !showOnMobile) {
    document.getElementById('site-runtime').style.display = 'none';
  }
</script>
    </div>
  </footer>

  
  <script size="300" alpha="0.6" zIndex="-1" src="https://cdn.jsdelivr.net/npm/ribbon.js@1.0.2/dist/ribbon.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@next-theme/pjax@0.5.0/pjax.min.js" integrity="sha256-3NkoLDrmHLTYj7csHIZSr0MHAFTXth7Ua/DDt4MRUAg=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.js" integrity="sha256-yt2kYMy0w8AbtF89WXb2P1rfjcP/HTHLT7097U8Y5b8=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/lozad.js/1.16.0/lozad.min.js" integrity="sha256-mOFREFhqmHeQbXpK2lp4nA3qooVgACfh88fpJftLBbc=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script><script src="/js/bookmark.js"></script><script src="/js/pjax.js"></script>

  
  <script src="https://embed.widgetpack.com/widget.js" async></script>
  <script class="next-config" data-name="rating" type="application/json">{"enable":true,"id":11277,"color":"f79533"}</script>
  <script src="/js/third-party/rating.js"></script>
<script src="https://cdn.jsdelivr.net/npm/hexo-generator-searchdb@1.4.0/dist/search.js" integrity="sha256-vXZMYLEqsROAXkEw93GGIvaB2ab+QW6w3+1ahD9nXXA=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>

  <script class="next-config" data-name="pdf" type="application/json">{"object_url":{"url":"https://cdnjs.cloudflare.com/ajax/libs/pdfobject/2.2.7/pdfobject.min.js","integrity":"sha256-ph3Dk89VmuTVXG6x/RDzk53SU9LPdAh1tpv0UvnDZ2I="},"url":"/lib/pdf/web/viewer.html"}</script>
  <script src="/js/third-party/tags/pdf.js"></script>


  <script src="/js/third-party/fancybox.js"></script>

  <script src="/js/third-party/pace.js"></script>

  
  <script data-pjax async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","mhchem":true,"js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.0/es5/tex-mml-chtml.js","integrity":"sha256-r+3itOMtGGjap0x+10hu6jW/gZCzxHsoKrOd7gyRSGY="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>


<script class="next-config" data-name="waline" type="application/json">{"lang":"zh-CN","enable":true,"serverURL":"waline-five-pi.vercel.app","cssUrl":"https://unpkg.com/@waline/client@v2/dist/waline.css","commentCount":true,"pageview":false,"libUrl":"https://unpkg.com/@waline/client@v2/dist/waline.js","locale":{"placeholder":"Welcome to comment"},"dark":"auto","emoji":["https://unpkg.com/@waline/emojis@1.0.1/weibo","https://unpkg.com/@waline/emojis@1.0.1/alus","https://unpkg.com/@waline/emojis@1.0.1/bilibili","https://unpkg.com/@waline/emojis@1.0.1/qq","https://unpkg.com/@waline/emojis@1.0.1/tieba","https://unpkg.com/@waline/emojis@1.0.1/tw-emoji"],"wordLimit":0,"pageSize":10,"el":"#waline","comment":true,"path":"/post/70b40a92.html"}</script>
<link rel="stylesheet" href="https://unpkg.com/@waline/client@v2/dist/waline.css">
<script>
document.addEventListener('page:loaded', () => {
  NexT.utils.loadComments(CONFIG.waline.el).then(() =>
    NexT.utils.getScript(CONFIG.waline.libUrl, { condition: window.Waline })
  ).then(() => 
    Waline.init(Object.assign({}, CONFIG.waline,{ el: document.querySelector(CONFIG.waline.el) }))
  );
});
</script>
<script src="https://unpkg.com/darkmode-js@1.5.7/lib/darkmode-js.min.js"></script>

<script>
var options = {
  bottom: '64px',
  right: '32px',
  left: 'unset',
  time: '0.5s',
  mixColor: 'transparent',
  backgroundColor: 'transparent',
  buttonColorDark: '#100f2c',
  buttonColorLight: '#fff',
  saveInCookies: true,
  label: '🌓',
  autoMatchOsTheme: true
}
const darkmode = new Darkmode(options);
window.darkmode = darkmode;
darkmode.showWidget();
</script>

</body>
</html>
