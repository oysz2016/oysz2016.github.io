<!DOCTYPE html><html class="theme-next gemini use-motion" lang="zh-Hans"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"><meta name="theme-color" content="#222"><script></script><script src="/lib/pace/pace.min.js?v=1.0.2"></script><link href="/lib/pace/pace-theme-minimal.min.css?v=1.0.2" rel="stylesheet"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><script>!function(e,t,o,c,i,a,n){e.DaoVoiceObject=i,e[i]=e[i]||function(){(e[i].q=e[i].q||[]).push(arguments)},e[i].l=1*new Date,a=t.createElement(o),n=t.getElementsByTagName(o)[0],a.async=1,a.src=c,a.charset="utf-8",n.parentNode.insertBefore(a,n)}(window,document,"script",("https:"==document.location.protocol?"https:":"http:")+"//widget.daovoice.io/widget/0f81ff2f.js","daovoice"),daovoice("init",{app_id:"116d2e76"}),daovoice("update")</script><link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css"><link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css"><link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css"><link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css"><link rel="apple-touch-icon" sizes="180x180" href="http://p7jiixmp8.bkt.clouddn.com/shanghai.png?v=5.1.4"><link rel="icon" type="image/png" sizes="32x32" href="http://p7jiixmp8.bkt.clouddn.com/32_32_shanghai.png?v=5.1.4"><link rel="icon" type="image/png" sizes="16x16" href="http://p7jiixmp8.bkt.clouddn.com/16_16_shanghai.png?v=5.1.4"><link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222"><meta name="keywords" content="深度学习,卷积神经网络,LeNet5,AlexNet,ZFNet,VGG16,GoogLeNet,ResNet,"><link rel="alternate" href="/atom.xml" title="冲弱's Blog" type="application/atom+xml"><meta name="description" content="&amp;emsp;&amp;emsp;在我的个人博客上一篇博文中分析了卷积神经网络的结构与相关算法，知道了这些基本原理之后。这篇博文主要介绍在卷积神经网络的发展历程中一些经典的网络模型。 LeNet5&amp;emsp;&amp;emsp;LeCun等将BP算法应用到多层神经网络中，提出LeNet-5模型[1]（效果和paper见此处），并将其用于手写数字识别，卷积神经网络才算正式提出。LeNet-5的网络模型如图1所示。网络"><meta name="keywords" content="深度学习,卷积神经网络,LeNet5,AlexNet,ZFNet,VGG16,GoogLeNet,ResNet"><meta property="og:type" content="article"><meta property="og:title" content="卷积神经网络模型解读汇总——LeNet5，AlexNet、ZFNet、VGG16、GoogLeNet和ResNet"><meta property="og:url" content="https://oysz2016.github.io/post/d86a012b.html"><meta property="og:site_name" content="冲弱&#39;s Blog"><meta property="og:description" content="&amp;emsp;&amp;emsp;在我的个人博客上一篇博文中分析了卷积神经网络的结构与相关算法，知道了这些基本原理之后。这篇博文主要介绍在卷积神经网络的发展历程中一些经典的网络模型。 LeNet5&amp;emsp;&amp;emsp;LeCun等将BP算法应用到多层神经网络中，提出LeNet-5模型[1]（效果和paper见此处），并将其用于手写数字识别，卷积神经网络才算正式提出。LeNet-5的网络模型如图1所示。网络"><meta property="og:locale" content="zh-Hans"><meta property="og:image" content="http://p7jiixmp8.bkt.clouddn.com/Blog/LeNet5网络模型.png-chuli"><meta property="og:image" content="http://p7jiixmp8.bkt.clouddn.com/Blog/LeNet5具体参数.png-chuli"><meta property="og:image" content="http://p7jiixmp8.bkt.clouddn.com/Blog/dropout.png-chuli"><meta property="og:image" content="http://p7jiixmp8.bkt.clouddn.com/Blog/AlexNet网络模型.png-chuli"><meta property="og:image" content="http://p7jiixmp8.bkt.clouddn.com/Blog/AlexNet具体参数2.png-chuli"><meta property="og:image" content="http://p7jiixmp8.bkt.clouddn.com/Blog/ZFNet网络模型.jpg-chuli"><meta property="og:image" content="http://p7jiixmp8.bkt.clouddn.com/Blog/ZFNet具体参数.png-chuli"><meta property="og:image" content="http://p7jiixmp8.bkt.clouddn.com/Blog/Vgg16网络结构2.jpg-chuli"><meta property="og:image" content="http://p7jiixmp8.bkt.clouddn.com/Blog/多层感知机.png-chuli"><meta property="og:image" content="http://p7jiixmp8.bkt.clouddn.com/Blog/Inception_naive.png-chuli"><meta property="og:image" content="http://p7jiixmp8.bkt.clouddn.com/Blog/Inception.png-chuli"><meta property="og:image" content="http://p7jiixmp8.bkt.clouddn.com/Blog/GoogLeNet网络模型.jpg-chuli"><meta property="og:image" content="http://p7jiixmp8.bkt.clouddn.com/Blog/GoogleNet具体参数.png-chuli"><meta property="og:image" content="http://p7jiixmp8.bkt.clouddn.com/Blog/退化现象.jpg-chuli"><meta property="og:image" content="http://p7jiixmp8.bkt.clouddn.com/Blog/Residual结构.png-chuli"><meta property="og:image" content="http://p7jiixmp8.bkt.clouddn.com/Blog/更深的residual block.png-chuli"><meta property="og:updated_time" content="2018-05-09T16:13:13.801Z"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="卷积神经网络模型解读汇总——LeNet5，AlexNet、ZFNet、VGG16、GoogLeNet和ResNet"><meta name="twitter:description" content="&amp;emsp;&amp;emsp;在我的个人博客上一篇博文中分析了卷积神经网络的结构与相关算法，知道了这些基本原理之后。这篇博文主要介绍在卷积神经网络的发展历程中一些经典的网络模型。 LeNet5&amp;emsp;&amp;emsp;LeCun等将BP算法应用到多层神经网络中，提出LeNet-5模型[1]（效果和paper见此处），并将其用于手写数字识别，卷积神经网络才算正式提出。LeNet-5的网络模型如图1所示。网络"><meta name="twitter:image" content="http://p7jiixmp8.bkt.clouddn.com/Blog/LeNet5网络模型.png-chuli"><script type="text/javascript" id="hexo.configurations">var NexT=window.NexT||{},CONFIG={root:"/",scheme:"Gemini",version:"5.1.4",sidebar:{position:"left",display:"post",offset:12,b2t:!1,scrollpercent:!0,onmobile:!0},fancybox:!0,tabs:!0,motion:{enable:!0,async:!1,transition:{post_block:"fadeIn",post_header:"slideDownIn",post_body:"slideDownIn",coll_header:"slideLeftIn",sidebar:"slideUpIn"}},duoshuo:{userId:"0",author:"博主"},algolia:{applicationID:"",apiKey:"",indexName:"",hits:{per_page:10},labels:{input_placeholder:"Search for Posts",hits_empty:"We didn't find any results for the search: ${query}",hits_stats:"${hits} results found in ${time} ms"}}}</script><link rel="canonical" href="https://oysz2016.github.io/post/d86a012b.html"><title>卷积神经网络模型解读汇总——LeNet5，AlexNet、ZFNet、VGG16、GoogLeNet和ResNet | 冲弱's Blog</title></head><body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans"><div class="container sidebar-position-left page-post-detail"><div class="headband"></div><header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="header-inner"><div class="site-brand-wrapper"><div class="site-meta"><div class="custom-logo-site-title"><a href="/" class="brand" rel="start"><span class="logo-line-before"><i></i></span> <span class="site-title">冲弱's Blog</span><span class="logo-line-after"><i></i></span></a></div><p class="site-subtitle">人生在勤，不索何获</p></div><div class="site-nav-toggle"> <button><span class="btn-bar"></span><span class="btn-bar"></span><span class="btn-bar"></span></button></div></div><nav class="site-nav"><ul id="menu" class="menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i><br> 首页</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i><br> 标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i><br> 分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i><br> 归档</a></li><li class="menu-item menu-item-comment"><a href="/comment/" rel="section"><i class="menu-item-icon fa fa-fw fa-comment"></i><br> 留言</a></li><li class="menu-item menu-item-search"><a href="javascript:;" class="st-search-show-outputs"><i class="menu-item-icon fa fa-search fa-fw"></i><br> 搜索</a></li></ul><div class="site-search"><form class="site-search-form"> <input type="text" id="st-search-input" class="st-search-input st-default-search-input"></form><script type="text/javascript">!function(e,t,n,s,c,i,o){e.SwiftypeObject=c,e[c]=e[c]||function(){(e[c].q=e[c].q||[]).push(arguments)},i=t.createElement(n),o=t.getElementsByTagName(n)[0],i.async=1,i.src="//s.swiftypecdn.com/install/v2/st.js",o.parentNode.insertBefore(i,o)}(window,document,"script",0,"_st"),_st("install","_fC1jT9UoSk9vQ72-ezz","2.0.0")</script></div></nav></div></header><main id="main" class="main"><div class="main-inner"><div class="content-wrap"><div id="content" class="content"><div id="posts" class="posts-expand"><article class="post post-type-normal" itemscope itemtype="http://schema.org/Article"><div class="post-block"><link itemprop="mainEntityOfPage" href="https://oysz2016.github.io/post/d86a012b.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="name" content="冲弱"><meta itemprop="description" content=""><meta itemprop="image" content="http://p7jiixmp8.bkt.clouddn.com/%E6%B4%BE%E5%A4%A7%E6%98%9F.png"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="冲弱's Blog"></span><header class="post-header"><h1 class="post-title" itemprop="name headline">卷积神经网络模型解读汇总——LeNet5，AlexNet、ZFNet、VGG16、GoogLeNet和ResNet</h1><div class="post-meta"><span class="post-time"><span class="post-meta-item-icon"><i class="fa fa-calendar-o"></i></span> <span class="post-meta-item-text">发表于</span> <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-04-26T16:43:22+08:00">2018-04-26</time></span> <span class="post-category"><span class="post-meta-divider">|</span><span class="post-meta-item-icon"><i class="fa fa-folder-o"></i></span> <span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/深度学习笔记/" itemprop="url" rel="index"><span itemprop="name">深度学习笔记</span></a></span></span> <span id="/post/d86a012b.html" class="leancloud_visitors" data-flag-title="卷积神经网络模型解读汇总——LeNet5，AlexNet、ZFNet、VGG16、GoogLeNet和ResNet"><span class="post-meta-divider">|</span><span class="post-meta-item-icon"><i class="fa fa-eye"></i></span> <span class="post-meta-item-text">阅读次数&#58;</span><span class="leancloud-visitors-count"></span></span><div class="post-wordcount"><span class="post-meta-item-icon"><i class="fa fa-file-word-o"></i></span> <span class="post-meta-item-text">字数统计&#58;</span> <span title="字数统计">3,243 字</span> <span class="post-meta-divider">|</span><span class="post-meta-item-icon"><i class="fa fa-clock-o"></i></span> <span class="post-meta-item-text">阅读时长 &asymp;</span> <span title="阅读时长">12 分钟</span></div></div></header><div class="post-body" itemprop="articleBody"><script src="\assets\js\APlayer.min.js"></script><p>&emsp;&emsp;在我的<a href="https://oysz2016.github.io/">个人博客</a>上一篇<a href="https://oysz2016.github.io/2018/04/25/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E7%BB%93%E6%9E%84%E4%B8%8E%E7%9B%B8%E5%85%B3%E7%AE%97%E6%B3%95/">博文</a>中分析了卷积神经网络的结构与相关算法，知道了这些基本原理之后。这篇博文主要介绍在卷积神经网络的发展历程中一些经典的网络模型。</p><h2 id="LeNet5"><a href="#LeNet5" class="headerlink" title="LeNet5"></a>LeNet5</h2><p>&emsp;&emsp;LeCun等将BP算法应用到多层神经网络中，提出LeNet-5模型[1]（<a href="http://yann.lecun.com/exdb/lenet/index.html" target="_blank" rel="noopener">效果和paper见此处</a>），并将其用于手写数字识别，卷积神经网络才算正式提出。LeNet-5的网络模型如图1所示。网络模型具体参数如图2所示。<br><a id="more"></a><br><img src="http://p7jiixmp8.bkt.clouddn.com/Blog/LeNet5网络模型.png-chuli" alt="enter description here"></p><p></p><div align="center">图1 LeNet-5网络模型</div><p></p><p></p><div align="center">表1 LeNet-5具体参数</div><br><img src="http://p7jiixmp8.bkt.clouddn.com/Blog/LeNet5具体参数.png-chuli" alt="enter description here"><br><strong>输入</strong>：32<em>32的手写字体图片，这些手写字体包含0~9数字，也就是相当于10个类别的图片;<br><em>*输出</em></em>：分类结果，0~9之间。<br>&emsp;&emsp;从输入输出可以知道，改网络解决的是一个十分类的问题，分类器使用的Softamx回归。<p></p><ul><li><strong>C1</strong>：卷积核参数如表所示。卷积的后的尺寸计算公式为：<script type="math/tex;mode=display">outHeight=(inHeight+2pad-filterHeight)/strides[1]+1</script><script type="math/tex;mode=display">outWidth=(inWidth+2pad-filterHidth)/strides[2] +1</script>&emsp;&emsp;因此，经过C1卷积层后，每个特征图大小为32-5+1=28，这一层输出的神经元个数为28<em>28</em>6=784。而这一层卷积操作的参数个数为5<em>5</em>1<em>6+6=156，其中参数个数与神经元个数无关，只与卷积核大小（此处为5</em>5），卷积核数量（此处为6，上一层图像默认深度为1）；</li><li><strong>S2</strong>：输入为28<em>28</em>6，该网络使用最大池化进行下采样，池化大小为2<em>2，经过池化操作后输出神经元个数为14</em>14*6；</li><li><strong>C3</strong>：经过C3层后，输出为10<em>10</em>16，参数个数为5<em>5</em>6*16+16=2416个参数；</li><li><strong>S4</strong>：输入为10<em>10</em>16，参数与S2层一致，池化后输出神经元个数为5<em>5</em>16；</li><li><strong>C5</strong>：经过C5层后，输出为1<em>1</em>120，参数个数为5<em>5</em>16<em>120+120=48120个参数。（这一层的卷积大小为5</em>5，图像的输入大小也为5*5，可等效为全连接层）；</li><li><strong>F6</strong>：输出为1<em>1</em>84，参数个数为1<em>1</em>120*84+84=10164<br>参数总量：60856</li></ul><p>&emsp;&emsp;从表1的具体参数可以看出，LeNet的网络结构十分简单且单一，卷积层C1、C3和C5层除了输出维数外采用的是相同的参数，池化层S2和S4采用的也是相同的参数</p><h2 id="AlexNet"><a href="#AlexNet" class="headerlink" title="AlexNet"></a>AlexNet</h2><p>&emsp;&emsp;2012年Krizhevsky使用卷积神经网络在ILSVRC 2012图像分类大赛上夺冠，提出了AlexNet模型[2]（<a href="https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf" target="_blank" rel="noopener">论文地址</a>）。这篇文章凭借着诸多创新的方法，促使了之后的神经网络研究浪潮。AlexNet网络的提出对于卷积神经网络具有里程碑式的意义，相比较于LeNet5的改进有以下几点</p><ol><li>数据增强</li></ol><ul><li>水平翻转</li><li>随机裁剪、平移变换</li><li>颜色光照变换</li></ul><ol><li>Dropout： Dropout方法和数据增强一样，都是防止过拟合的。简单的说，dropout能按照一定的概率将神经元从网络中丢弃。一个很形象的解释如图2所示，左图为dropout前，右图为dropout后。dropout能在一定程度上防止网络过拟合，并且能加快网络的训练速度。<br><img src="http://p7jiixmp8.bkt.clouddn.com/Blog/dropout.png-chuli" alt="enter description here"><div align="center">图2 Dropout示意图</div></li><li>ReLU激活函数：ReLu具有一些优良特性，在为网络引入非线性的同时，也能引入稀疏性。稀疏性可以选择性激活和分布式激活神经元，能学习到相对稀疏的特征，起到自动化解离的效果。此外，ReLu的导数曲线在输入大于0时，函数的导数为1，这种特性能保证在输入大于0时梯度不衰减，从而避免或抑制网络训练时的梯度消失现象，网络模型的收敛速度会相对稳定[10]。</li><li>Local Response Normalization：Local Response Normalization要硬翻译的话是局部响应归一化，简称LRN，实际就是利用临近的数据做归一化。这个策略贡献了1.2%的Top-5错误率。</li><li>Overlapping Pooling：Overlapping的意思是有重叠，即Pooling的步长比Pooling Kernel的对应边要小。这个策略贡献了0.3%的Top-5错误率。</li><li>多GPU并行：这个太重要了，入坑了后发现深度学习真是“炼丹”的学科。得益于计算机硬件的发展，在我自己训练时，Gpu大概能比Cpu快一个数量级以上。能极大的加快网络训练。<br>AlextNet的网络结构如图3所示，具体参数如表2所示。<br><img src="http://p7jiixmp8.bkt.clouddn.com/Blog/AlexNet网络模型.png-chuli" alt="enter description here"><br><div align="center">图3 AlexNet网络模型</div><br><div align="center">表2 AlexNet具体参数</div><br><img src="http://p7jiixmp8.bkt.clouddn.com/Blog/AlexNet具体参数2.png-chuli" alt="enter description here"><br><strong>输入</strong>：224<em>224</em>3（RGB图像），图像会经过预处理变为227<em>227</em>3;<br><strong>输出</strong>：使用的是ImageNet数据集，该数据集有1000个类，因此输出的类别也是1000个。<br>&emsp;&emsp;从输入输出可以知道，改网络解决的是一个十分类的问题，分类器使用的Softamx回归。<ul><li><strong>conv1</strong>：输出为55<em>55</em>96，参数个数为11<em>11</em>3*96+96=34944</li><li><strong>pool1</strong>：输出为27<em>27</em>96；</li><li><strong>conv2</strong>：输出为27<em>27</em>256，参数个数为5<em>5</em>96*256+256=614656</li><li><strong>pool2</strong>：输出为13<em>13</em>256；</li><li><strong>conv3</strong>：输出为13<em>13</em>384，参数个数为3<em>3</em>256*384+384=885120</li><li><strong>conv4</strong>：输出为13<em>13</em>384，参数个数为3<em>3</em>384*384+384=1327488</li><li><strong>conv5</strong>：输出为13<em>13</em>256，参数个数为3<em>3</em>384*256+256=884992</li><li><strong>pool3</strong>：输出为6<em>6</em>256；</li><li><strong>fc6</strong>：输出为1<em>1</em>4096，参数个数为1<em>1</em>256*4096+4096=1052672</li><li><strong>fc7</strong>：输出为1<em>1</em>4096，参数个数为1<em>1</em>4096*4096+4096=16781312<br>参数总量：21581184</li></ul></li></ol><p>&emsp;&emsp;通过对比LeNet-5和AlexNet的网络结构可以看出，AlexNet具有更深的网络结构，更多的参数。</p><h2 id="ZFNet"><a href="#ZFNet" class="headerlink" title="ZFNet"></a>ZFNet</h2><p>&emsp;&emsp;ZFNet[3]（<a href="https://arxiv.org/pdf/1311.2901.pdf" target="_blank" rel="noopener">论文地址</a>）是由纽约大学的Matthew Zeiler和Rob Fergus所设计，该网络在AlexNet上进行了微小的改进，但这篇文章主要贡献在于在一定程度上解释了卷积神经网络为什么有效，以及如何提高网络的性能。该网络的贡献在于：</p><ul><li>使用了反卷积网络，可视化了特征图。通过特征图证明了浅层网络学习到了图像的边缘、颜色和纹理特征，高层网络学习到了图像的抽象特征；</li><li>根据特征可视化，提出AlexNet第一个卷积层卷积核太大，导致提取到的特征模糊；</li><li>通过几组遮挡实验，对比分析找出了图像的关键部位；</li><li>论证了更深的网络模型，具有更好的性能。</li></ul><p>&emsp;&emsp;ZFNet的网络模型如图4所示，具体参数如表3所示。<br><img src="http://p7jiixmp8.bkt.clouddn.com/Blog/ZFNet网络模型.jpg-chuli" alt="enter description here"></p><div align="center">图4 ZFNet网络模型</div><br><div align="center">表3 ZFNet具体参数</div><br> <img src="http://p7jiixmp8.bkt.clouddn.com/Blog/ZFNet具体参数.png-chuli" alt="enter description here"><br>&emsp;&emsp;ZFNet的网络模型与AlexNet十分相似，这里就不列举每一层的输入输出了。<p></p><h2 id="VGG16"><a href="#VGG16" class="headerlink" title="VGG16"></a>VGG16</h2><p>&emsp;&emsp;VGGNet[4]是由牛津大学计算机视觉组和Google DeepMind项目的研究员共同研发的卷积神经网络模型，包含VGG16和VGG19两种模型，其网络模型如图5所示，<a href="http://ethereon.github.io/netscope/#/gist/dc5003de6943ea5a6b8b" target="_blank" rel="noopener">也可以点击此处链接</a>查看网络模型。<br><img src="http://p7jiixmp8.bkt.clouddn.com/Blog/Vgg16网络结构2.jpg-chuli" alt="enter description here"></p><div align="center">图5 VGG16网络模型</div><br>&emsp;&emsp;从网络模型可以看出，VGG16相比AlexNet类的模型具有较深的深度，通过反复堆叠3<em>3的卷积层和2</em>2的池化层，VGG16构建了较深层次的网络结构，整个网络的卷积核使用了一致的3<em>3的尺寸，最大池化层尺寸也一致为2</em>2。与AlexNet主要有以下不同：<p></p><ul><li>Vgg16有16层网络，AlexNet只有8层；</li><li>在训练和测试时使用了多尺度做数据增强。</li></ul><h2 id="GoogLeNet"><a href="#GoogLeNet" class="headerlink" title="GoogLeNet"></a>GoogLeNet</h2><p>&emsp;&emsp;GoogLeNet[5]（<a href="https://arxiv.org/pdf/1409.4842.pdf" target="_blank" rel="noopener">论文地址</a>）进一步增加了网络模型的深度和宽度，但是单纯的在VGG16的基础上增加网络的宽度深度会带来以下缺陷：</p><ul><li>过多的参数容易引起过拟合；</li><li>层数的加深，容易引起梯度消失现象。</li></ul><p>&emsp;&emsp;GoogLeNet的提出受到论文Network in Network（NIN）的启发，NIN有两个贡献：</p><ul><li>提出多层感知卷积层：使用卷积层后加上多层感知机，增强网络提取特征的能力。普通的卷积层和多层感知卷积层的结构图如图6所示，Mlpconv相当于在一般的卷积层后加了一个1*1的卷积层；<br><img src="http://p7jiixmp8.bkt.clouddn.com/Blog/多层感知机.png-chuli" alt="enter description here"><div align="center">图6 普通卷积层和多层感知卷积层结构图</div></li><li>提出了全局平均池化替代全连接层，从上文计算的LeNet5，AlexNet网络各层的参数数量发现，全连接层具有大量的参数。使用全局平均池化替代全连接层，能很大程度减少参数空间，便于加深网络，还能防止过拟合。</li></ul><p>&emsp;&emsp;GoogLeNet根据Mlpconv的思想提出了Inception结构，该结构有两个版本，图7是Inception的naive版。该结构巧妙的将1<em>1、3</em>3和5*5三种卷积核和最大池化层结合起来作为一层结构。<br><img src="http://p7jiixmp8.bkt.clouddn.com/Blog/Inception_naive.png-chuli" alt="enter description here"></p><p></p><div align="center">图7 Inception结构的naive版</div><br>&emsp;&emsp;然而Inception的naive版中5<em>5的卷积核会带来很大的计算量，因此采用了与NIN类似的结构，在原始的卷积层之后加上了1</em>1卷积层，最终版本的Inception如图8所示。<p></p><p><img src="http://p7jiixmp8.bkt.clouddn.com/Blog/Inception.png-chuli" alt="图8 降维后的Inception模块"></p><p></p><div align="center">图8 降维后的Inception模块</div><br>&emsp;&emsp;GoogLeNet的模型结构如图9所示，详细参数如表4所示。<br><img src="http://p7jiixmp8.bkt.clouddn.com/Blog/GoogLeNet网络模型.jpg-chuli" alt="enter description here"><p></p><p></p><div align="center">图9 GoogLeNet模型结构</div><p></p><p></p><div align="center">表4 GoogLeNet具体参数</div><br><img src="http://p7jiixmp8.bkt.clouddn.com/Blog/GoogleNet具体参数.png-chuli" alt="enter description here"><p></p><h2 id="ResNet"><a href="#ResNet" class="headerlink" title="ResNet"></a>ResNet</h2><p>&emsp;&emsp;卷积神经网络模型的发展历程一次次证明加深网络的深度和宽度能得到更好的效果，但是后来的研究发现，网络层次较深的网络模型的效果反而会不如较浅层的网络，称为“退化”现象，如图10所示。<br><img src="http://p7jiixmp8.bkt.clouddn.com/Blog/退化现象.jpg-chuli" alt="enter description here"></p><p></p><div align="center">图10 退化现象</div><br>&emsp;&emsp;退化现象产生的原因在于当模型的结构变得复杂时，随机梯度下降的优化变得更加困难，导致网络模型的效果反而不如浅层网络。针对这个问题，MSRA何凯明团队提出了Residual Networks<a href="[论文地址](https://arxiv.org/pdf/1512.03385.pdf">6</a>)。该网络具有Residual结构如图11所示。<p></p><p> <img src="http://p7jiixmp8.bkt.clouddn.com/Blog/Residual结构.png-chuli" alt="enter description here"></p><p></p><div align="center">图11 Residual 结构</div><br>&emsp;&emsp;ResNet的基本思想是引入了能够跳过一层或多层的“shortcut connection”，即增加一个identity mapping（恒等映射），将原始所需要学的函数H(x)转换成F(x)+x，而作者认为这两种表达的效果相同，但是优化的难度却并不相同，作者假设F(x)的优化 会比H(x)简单的多。这一想法也是源于图像处理中的残差向量编码，通过一个reformulation，将一个问题分解成多个尺度直接的残差问题，能够很好的起到优化训练的效果。<br>&emsp;&emsp;这个Residual block通过shortcut connection实现，通过shortcut将这个block的输入和输出进行一个element-wise的加叠，这个简单的加法并不会给网络增加额外的参数和计算量，同时却可以大大增加模型的训练速度、提高训练效果，并且当模型的层数加深时，这个简单的结构能够很好的解决退化问题。<br>&emsp;&emsp;首先构建了一个18层和一个34层的plain网络，即将所有层进行简单的铺叠，然后构建了一个18层和一个34层的residual网络，仅仅是在plain上插入了shortcut，而且这两个网络的参数量、计算量相同，并且和之前有很好效果的VGG-19相比，计算量要小很多。（36亿FLOPs VS 196亿FLOPs，FLOPs即每秒浮点运算次数。）这也是作者反复强调的地方，也是这个模型最大的优势所在。<br>&emsp;&emsp;模型构建好后进行实验，在plain上观测到明显的退化现象，而且ResNet上不仅没有退化，34层网络的效果反而比18层的更好，而且不仅如此，ResNet的收敛速度比plain的要快得多。<br>对于shortcut的方式，作者提出了三个策略：<p></p><ul><li>使用恒等映射，如果residual block的输入输出维度不一致，对增加的维度用0来填充；</li><li>在block输入输出维度一致时使用恒等映射，不一致时使用线性投影以保证维度一致；</li><li>对于所有的block均使用线性投影。<br>ResNet论文的最后探讨了阻碍网络更深的瓶颈问题，如图12所示，论文中用三个1x1,3x3,1x1的卷积层代替前面说的两个3x3卷积层，第一个1x1用来降低维度，第三个1x1用来增加维度，这样可以保证中间的3x3卷积层拥有比较小的输入输出维度。<br><img src="http://p7jiixmp8.bkt.clouddn.com/Blog/更深的residual block.png-chuli" alt="enter description here"><br><div align="center">图12 更深的residual block</div><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2>[1] Lecun Y, Bottou L, Bengio Y, et al. Gradient-based learning applied to document recognition[J]. Proceedings of the IEEE, 1998, 86(11):2278-2324.<br>[2] Krizhevsky A, Sutskever I, Hinton G E. ImageNet classification with deep convolutional neural networks[C]// International Conference on Neural Information Processing Systems. Curran Associates Inc. 2012:1097-1105.<br>[3] Zeiler M D, Fergus R. Visualizing and Understanding Convolutional Networks[J]. 2013, 8689:818-833.<br>[4] Simonyan K, Zisserman A. Very Deep Convolutional Networks for Large-Scale Image Recognition[J]. Computer Science, 2014.<br>[5] Szegedy C, Liu W, Jia Y, et al. Going deeper with convolutions[C]// IEEE Conference on Computer Vision and Pattern Recognition. IEEE Computer Society, 2015:1-9.<br>[6] He K, Zhang X, Ren S, et al. Deep Residual Learning for Image Recognition[C]// Computer Vision and Pattern Recognition. IEEE, 2016:770-778.</li></ul></div><div><div><div style="text-align:center;color:#ccc;font-size:14px">-------------本文结束<i class="fa fa-smile-o"></i>感谢您的阅读-------------</div></div></div><div><div style="padding:10px 0;margin:20px auto;width:90%;text-align:center"><div>坚持原创技术分享，您的支持将鼓励我继续创作！</div> <button id="rewardButton" disable="enable" onclick='var qr=document.getElementById("QR");"none"===qr.style.display?qr.style.display="block":qr.style.display="none"'> <span>打赏</span></button><div id="QR" style="display:none"><div id="wechat" style="display:inline-block"> <img id="wechat_qr" src="http://p7jiixmp8.bkt.clouddn.com/wechatpay.jpg" alt="冲弱 微信支付"><p>微信支付</p></div><div id="alipay" style="display:inline-block"> <img id="alipay_qr" src="http://p7jiixmp8.bkt.clouddn.com/alipay.jpg" alt="冲弱 支付宝"><p>支付宝</p></div></div></div></div><footer class="post-footer"><div class="post-tags"><a href="/tags/深度学习/" rel="tag"><i class="fa fa-tag"></i> 深度学习</a><a href="/tags/卷积神经网络/" rel="tag"><i class="fa fa-tag"></i> 卷积神经网络</a><a href="/tags/LeNet5/" rel="tag"><i class="fa fa-tag"></i> LeNet5</a><a href="/tags/AlexNet/" rel="tag"><i class="fa fa-tag"></i> AlexNet</a><a href="/tags/ZFNet/" rel="tag"><i class="fa fa-tag"></i> ZFNet</a><a href="/tags/VGG16/" rel="tag"><i class="fa fa-tag"></i> VGG16</a><a href="/tags/GoogLeNet/" rel="tag"><i class="fa fa-tag"></i> GoogLeNet</a><a href="/tags/ResNet/" rel="tag"><i class="fa fa-tag"></i> ResNet</a></div><div><div class="my_post_copyright"><script src="//cdn.bootcss.com/clipboard.js/1.5.10/clipboard.min.js"></script><script type="text/javascript" src="http://jslibs.wuxubj.cn/sweetalert_mini/jquery-1.7.1.min.js"></script><script src="http://jslibs.wuxubj.cn/sweetalert_mini/sweetalert.min.js"></script><link rel="stylesheet" type="text/css" href="http://jslibs.wuxubj.cn/sweetalert_mini/sweetalert.mini.css"><p><span>本文标题:</span>卷积神经网络模型解读汇总——LeNet5，AlexNet、ZFNet、VGG16、GoogLeNet和ResNet</p><p><span>文章作者:</span>冲弱</p><p><span>发布时间:</span>2018年04月26日 - 16:43:22</p><p><span>最后更新:</span>2018年05月10日 - 00:13:13</p><p><span>原始链接:</span><a href="/post/d86a012b.html" title="卷积神经网络模型解读汇总——LeNet5，AlexNet、ZFNet、VGG16、GoogLeNet和ResNet">https://oysz2016.github.io/post/d86a012b.html</a><span class="copy-path" title="点击复制文章链接"><i class="fa fa-clipboard" data-clipboard-text="https://oysz2016.github.io/post/d86a012b.html" aria-label="复制成功！"></i></span></p><p><span>许可协议:</span><i class="fa fa-creative-commons"></i> <a rel="license" href="https://creativecommons.org/licenses/by-nc-nd/4.0/" target="_blank" title="Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0)">署名-非商业性使用-禁止演绎 4.0 国际</a> 转载请保留原文链接及作者。</p></div><script>var clipboard=new Clipboard(".fa-clipboard");clipboard.on("success",$(function(){$(".fa-clipboard").click(function(){swal({title:"",text:"复制成功",html:!1,timer:500,showConfirmButton:!1})})}))</script></div><div class="post-widgets"><div class="wp_rating"> 给我的文章打个分吧&lt<div id="wpac-rating"></div></div></div><div class="post-nav"><div class="post-nav-next post-nav-item"><a href="/post/4ec18e58.html" rel="next" title="卷积神经网络的结构与相关算法"><i class="fa fa-chevron-left"></i> 卷积神经网络的结构与相关算法</a></div><span class="post-nav-divider"></span><div class="post-nav-prev post-nav-item"> <a href="/post/79a2296e.html" rel="prev" title="Caffe版Faster R-CNN可视化——网络模型,图像特征,Loss图,PR曲线">Caffe版Faster R-CNN可视化——网络模型,图像特征,Loss图,PR曲线<i class="fa fa-chevron-right"></i></a></div></div></footer></div></article><div class="post-spread"><div class="addthis_inline_share_toolbox"><script type="text/javascript" src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5adaebc9009ff58b" async="async"></script></div></div></div></div><div class="comments" id="comments"><div id="lv-container" data-id="city" data-uid="MTAyMC8zNTg2Ni8xMjQwMg=="></div></div></div><div class="sidebar-toggle"><div class="sidebar-toggle-line-wrap"><span class="sidebar-toggle-line sidebar-toggle-line-first"></span><span class="sidebar-toggle-line sidebar-toggle-line-middle"></span><span class="sidebar-toggle-line sidebar-toggle-line-last"></span></div></div><aside id="sidebar" class="sidebar"><div id="sidebar-dimmer"></div><div class="sidebar-inner"><ul class="sidebar-nav motion-element"><li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap"> 文章目录</li><li class="sidebar-nav-overview" data-target="site-overview-wrap"> 站点概览</li></ul><section class="site-overview-wrap sidebar-panel"><div class="site-overview"><div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person"> <a href="/" class="site-author-image" rel="start" style="border:none"><img class="site-author-image" itemprop="image" src="http://p7jiixmp8.bkt.clouddn.com/%E6%B4%BE%E5%A4%A7%E6%98%9F.png" alt="冲弱"></a><p class="site-author-name" itemprop="name">冲弱</p><p class="site-description motion-element" itemprop="description">输出即获得，分享即反哺</p></div><nav class="site-state motion-element"><div class="site-state-item site-state-posts"> <a href="/archives/"><span class="site-state-item-count">9</span> <span class="site-state-item-name">日志</span></a></div><div class="site-state-item site-state-categories"> <a href="/categories/index.html"><span class="site-state-item-count">4</span> <span class="site-state-item-name">分类</span></a></div><div class="site-state-item site-state-tags"> <a href="/tags/index.html"><span class="site-state-item-count">23</span> <span class="site-state-item-name">标签</span></a></div></nav><div class="feed-link motion-element"><a href="/atom.xml" rel="alternate"><i class="fa fa-rss"></i> RSS</a><a title="把这个链接拖到你的工具栏中,任何网页都可以High" href='javascript:(
    /*
     * Copyright (C) 2016 Never_yu (Neveryu.github.io) <React.dong.yu@gmail.com>
     * Sina Weibo (http://weibo.com/Neveryu)
     *
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     *      http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     */
    function go() {


    var songs = ["http://p7jiixmp8.bkt.clouddn.com/%E5%B0%8F%E9%AD%82%20-%20%E7%A6%BB%E4%BA%BA%E6%84%81%EF%BC%88Cover%20%E6%9B%B2%E8%82%96%E5%86%B0%EF%BC%89%20%28clip%29.mp3","http://p7jiixmp8.bkt.clouddn.com/%E5%9B%9E%E5%BF%86%E9%82%A3%E4%B9%88%E4%BC%A4_190649.mp3","http://p7jiixmp8.bkt.clouddn.com/%E7%94%9F%E6%97%A5%E5%BF%AB%E4%B9%90strong%28clip%29.mp3","http://p7jiixmp8.bkt.clouddn.com/%E8%A5%BF%E7%93%9CJUN%20-%20%E7%8B%82%E9%87%8E%E6%83%B3%E4%B9%A12%20%28clip%29.mp3"
    ];

    
    function c() {
        var e = document.createElement("link");
        e.setAttribute("type", "text/css");
        e.setAttribute("rel", "stylesheet");
        e.setAttribute("href", f);
        e.setAttribute("class", l);
        document.body.appendChild(e)
    }
 
    function h() {
        var e = document.getElementsByClassName(l);
        for (var t = 0; t < e.length; t++) {
            document.body.removeChild(e[t])
        }
    }
 
    function p() {
        var e = document.createElement("div");
        e.setAttribute("class", a);
        document.body.appendChild(e);
        setTimeout(function() {
            document.body.removeChild(e)
        }, 100)
    }
 
    function d(e) {
        return {
            height : e.offsetHeight,
            width : e.offsetWidth
        }
    }
 
    function v(i) {
        var s = d(i);
        return s.height > e && s.height < n && s.width > t && s.width < r
    }
 
    function m(e) {
        var t = e;
        var n = 0;
        while (!!t) {
            n += t.offsetTop;
            t = t.offsetParent
        }
        return n
    }
 
    function g() {
        var e = document.documentElement;
        if (!!window.innerWidth) {
            return window.innerHeight
        } else if (e && !isNaN(e.clientHeight)) {
            return e.clientHeight
        }
        return 0
    }
 
    function y() {
        if (window.pageYOffset) {
            return window.pageYOffset
        }
        return Math.max(document.documentElement.scrollTop, document.body.scrollTop)
    }
 
    function E(e) {
        var t = m(e);
        return t >= w && t <= b + w
    }

    function S() {
        var e = document.getElementById("audio_element_id");
        if(e != null){
            var index = parseInt(e.getAttribute("curSongIndex"));
            if(index > songs.length - 2) {
                index = 0;
            } else {
                index++;
            }
            e.setAttribute("curSongIndex", index);
            N();
        }

        e.src = i;
        e.play()
    }
 
    function x(e) {
        e.className += " " + s + " " + o
    }
 
    function T(e) {
        e.className += " " + s + " " + u[Math.floor(Math.random() * u.length)]
    }
 
    function N() {
        var e = document.getElementsByClassName(s);
        var t = new RegExp("\\b" + s + "\\b");
        for (var n = 0; n < e.length; ) {
            e[n].className = e[n].className.replace(t, "")
        }
    }

    function initAudioEle() {
        var e = document.getElementById("audio_element_id");
        if(e === null){
            e = document.createElement("audio");
            e.setAttribute("class", l);
            e.setAttribute("curSongIndex", 0);
            e.id = "audio_element_id";
            e.loop = false;
            e.bgcolor = 0;
            e.addEventListener("canplay", function() {
            setTimeout(function() {
                x(k)
            }, 500);
            setTimeout(function() {
                N();
                p();
                for (var e = 0; e < O.length; e++) {
                    T(O[e])
                }
            }, 15500)
        }, true);
        e.addEventListener("ended", function() {
            N();
            h();
            go();
        }, true);
        e.innerHTML = " <p>If you are reading this, it is because your browser does not support the audio element. We recommend that you get a new browser.</p> <p>";
        document.body.appendChild(e);
        }
    }
    
    initAudioEle();
    var e = 30;
    var t = 30;
    var n = 350;
    var r = 350;

    var curSongIndex = parseInt(document.getElementById("audio_element_id").getAttribute("curSongIndex"));
    var i = songs[curSongIndex];
    
    var s = "mw-harlem_shake_me";
    var o = "im_first";
    var u = ["im_drunk", "im_baked", "im_trippin", "im_blown"];
    var a = "mw-strobe_light";

    /* harlem-shake-style.css，替换成你的位置，也可以直接使用：//s3.amazonaws.com/moovweb-marketing/playground/harlem-shake-style.css */
    var f = "//s3.amazonaws.com/moovweb-marketing/playground/harlem-shake-style.css";
    
    var l = "mw_added_css";
    var b = g();
    var w = y();
    var C = document.getElementsByTagName("*");
    var k = null;
    for (var L = 0; L < C.length; L++) {
        var A = C[L];
        if (v(A)) {
            if (E(A)) {
                k = A;
                break
            }
        }
    }
    if (A === null) {
        console.warn("Could not find a node of the right size. Please try a different page.");
        return
    }
    c();
    S();
    var O = [];
    for (var L = 0; L < C.length; L++) {
        var A = C[L];
        if (v(A)) {
            O.push(A)
        }
    }
    })()'><i class="fa fa-music"></i> ShakeMusic!</a></div><div class="links-of-author motion-element"><span class="links-of-author-item"><a href="https://github.com/oysz2016" target="_blank" title="GitHub"><i class="fa fa-fw fa-github"></i> GitHub</a></span><span class="links-of-author-item"><a href="mailto:ouyang-sz@foxmail.com" target="_blank" title="E-Mail"><i class="fa fa-fw fa-envelope"></i> E-Mail</a></span><span class="links-of-author-item"><a href="https://juejin.im/user/5ae26032f265da0b9f3ffeb2" target="_blank" title="掘金"><i class="fa fa-fw fa-spinner"></i> 掘金</a></span><span class="links-of-author-item"><a href="https://www.jianshu.com/u/d6119d98a96a" target="_blank" title="简书"><i class="fa fa-fw fa-book"></i> 简书</a></span></div><div id="days"></div><script language="javascript">function show_date_time(){window.setTimeout("show_date_time()",1e3),BirthDay=new Date("04/22/2018 15:00:00"),today=new Date,timeold=today.getTime()-BirthDay.getTime(),sectimeold=timeold/1e3,secondsold=Math.floor(sectimeold),msPerDay=864e5,e_daysold=timeold/msPerDay,daysold=Math.floor(e_daysold),e_hrsold=24*(e_daysold-daysold),hrsold=setzero(Math.floor(e_hrsold)),e_minsold=60*(e_hrsold-hrsold),minsold=setzero(Math.floor(60*(e_hrsold-hrsold))),seconds=setzero(Math.floor(60*(e_minsold-minsold))),document.getElementById("days").innerHTML="已运行"+daysold+"天"+hrsold+"小时"+minsold+"分"+seconds+"秒"}function setzero(e){return e<10&&(e="0"+e),e}show_date_time()</script></div></section><section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active"><div class="post-toc"><div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#LeNet5"><span class="nav-number">1.</span> <span class="nav-text">LeNet5</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#AlexNet"><span class="nav-number">2.</span> <span class="nav-text">AlexNet</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#ZFNet"><span class="nav-number">3.</span> <span class="nav-text">ZFNet</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#VGG16"><span class="nav-number">4.</span> <span class="nav-text">VGG16</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#GoogLeNet"><span class="nav-number">5.</span> <span class="nav-text">GoogLeNet</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#ResNet"><span class="nav-number">6.</span> <span class="nav-text">ResNet</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#参考文献"><span class="nav-number">7.</span> <span class="nav-text">参考文献</span></a></li></ol></div></div></section></div></aside></div></main><footer id="footer" class="footer"><div class="footer-inner"><script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script><div class="copyright">&copy; <span itemprop="copyrightYear">2018</span><span class="with-love" id="heart"><i class="fa fa-heart"></i></span> <span class="author" itemprop="copyrightHolder">冲弱</span></div><div class="powered-by"><i class="fa fa-user-md"></i> <span id="busuanzi_container_site_uv">本站访客数:<span id="busuanzi_value_site_uv"></span></span></div> <span class="post-meta-divider">|</span><div class="theme-info"><div class="powered-by"></div> <span class="post-count">博客全站共26.2k字</span></div><div class="weixin-box"><div class="weixin-menu"><div class="weixin-hover"><div class="weixin-description">微信扫一扫，订阅本博客</div></div></div></div></div></footer><div class="back-to-top"><i class="fa fa-arrow-up"></i> <span id="scrollpercent"><span>0</span>%</span></div></div><script type="text/javascript">"[object Function]"!==Object.prototype.toString.call(window.Promise)&&(window.Promise=null)</script><script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script><script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script><script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script><script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script><script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script><script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script><script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script><script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script><script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script><script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script><script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script><script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script><script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script><script type="text/javascript">!function(e,t){var n,c=e.getElementsByTagName(t)[0];"function"!=typeof LivereTower&&((n=e.createElement(t)).src="https://cdn-city.livere.com/js/embed.dist.js",n.async=!0,c.parentNode.insertBefore(n,c))}(document,"script")</script><script src="https://cdn1.lncld.net/static/js/av-core-mini-0.6.4.js"></script><script>AV.initialize("7yvqM96LoALQrcwK8vCi5wPx-gzGzoHsz","shWOzxYkisgnXyjW2U3Ldj9V")</script><script>function showTime(e){var t=new AV.Query(e),c=[],u=$(".leancloud_visitors");u.each(function(){c.push($(this).attr("id").trim())}),t.containedIn("url",c),t.find().done(function(e){var t=".leancloud-visitors-count";if(0!==e.length){for(var n=0;n<e.length;n++){var o=e[n],i=o.get("url"),s=o.get("time"),r=document.getElementById(i);$(r).find(t).text(s)}for(n=0;n<c.length;n++){i=c[n],r=document.getElementById(i);var l=$(r).find(t);""==l.text()&&l.text(0)}}else u.find(t).text(0)}).fail(function(e,t){console.log("Error: "+t.code+" "+t.message)})}function addCount(i){var e=$(".leancloud_visitors"),s=e.attr("id").trim(),r=e.attr("data-flag-title").trim(),t=new AV.Query(i);t.equalTo("url",s),t.find({success:function(e){if(0<e.length){var t=e[0];t.fetchWhenSave(!0),t.increment("time"),t.save(null,{success:function(e){$(document.getElementById(s)).find(".leancloud-visitors-count").text(e.get("time"))},error:function(e,t){console.log("Failed to save Visitor num, with error message: "+t.message)}})}else{var n=new i,o=new AV.ACL;o.setPublicReadAccess(!0),o.setPublicWriteAccess(!0),n.setACL(o),n.set("title",r),n.set("url",s),n.set("time",1),n.save(null,{success:function(e){$(document.getElementById(s)).find(".leancloud-visitors-count").text(e.get("time"))},error:function(e,t){console.log("Failed to create")}})}},error:function(e){console.log("Error:"+e.code+" "+e.message)}})}$(function(){var e=AV.Object.extend("Counter");1==$(".leancloud_visitors").length?addCount(e):1<$(".post-title-link").length&&showTime(e)})</script><script type="text/javascript">wpac_init=window.wpac_init||[],wpac_init.push({widget:"Rating",id:11277,el:"wpac-rating",color:"f79533"}),function(){if(!("WIDGETPACK_LOADED"in window)){WIDGETPACK_LOADED=!0;var e=document.createElement("script");e.type="text/javascript",e.async=!0,e.src="//embed.widgetpack.com/widget.js";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t.nextSibling)}}()</script><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-backstretch/2.0.4/jquery.backstretch.min.js"></script>;<script>$("body").backstretch("http://p7jiixmp8.bkt.clouddn.com/WallpaperStudio10-81831.jpg")</script></body></html><script type="text/javascript" src="/js/src/love.js"></script>