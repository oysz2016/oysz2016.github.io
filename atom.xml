<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>冲弱&#39;s Blog</title>
  <icon>https://www.gravatar.com/avatar/ab8296a41c8b88ea9f8a771cd548cb5e</icon>
  <subtitle>少年无为，卖马为生</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://oysz2016.github.io/"/>
  <updated>2018-04-25T04:34:20.145Z</updated>
  <id>https://oysz2016.github.io/</id>
  
  <author>
    <name>冲弱</name>
    <email>ouyang-sz@foxmail.com</email>
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>卷积神经网络的结构与相关算法</title>
    <link href="https://oysz2016.github.io/2018/04/25/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E7%BB%93%E6%9E%84%E4%B8%8E%E7%9B%B8%E5%85%B3%E7%AE%97%E6%B3%95/"/>
    <id>https://oysz2016.github.io/2018/04/25/卷积神经网络的结构与相关算法/</id>
    <published>2018-04-25T04:08:42.925Z</published>
    <updated>2018-04-25T04:34:20.145Z</updated>
    
    <content type="html"><![CDATA[<h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>&emsp;&emsp;早在上世纪50年代，美国神经生物学家David Hubel通过研究猫和猴子的瞳孔区域与大脑皮层神经元的对应关系就发现视觉系统的信息处理方式是分级的。这一发现，促成了神经网络在图像处理上的发展。<a id="more"></a><br>&emsp;&emsp;神经网络的发展史可以分为三个阶段，第一个阶段是Frank Rosenblatt提出的感知机模型[1]，感知机模型的逻辑简单有效，但不能处理异或等非线性问题。第二个阶段是Rumelhart等提出的反向传播算法[2]，该算法使用梯度更新权值，使多层神经网络的训练成为可能。第三个阶段得益于计算机硬件的发展和大数据时代的到来，促进了深度神经网络的发展。<br>在上一篇博客<a href="https://oysz2016.github.io/2018/04/24/%E4%BB%80%E4%B9%88%E6%98%AF%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">什么是深度学习</a>中介绍了深度学习的三种网络模型，其中卷积神经网络在图像处理上有着诸多突破性的进展。由于我对卷积神经网络较为熟悉，下面将根据神经网络的三个发展阶段阶段分析讨论卷积神经网络的发展史。</p><h2 id="传统神经网络"><a href="#传统神经网络" class="headerlink" title="传统神经网络"></a>传统神经网络</h2><h3 id="感知机与多层网络"><a href="#感知机与多层网络" class="headerlink" title="感知机与多层网络"></a>感知机与多层网络</h3><p>&emsp;&emsp;感知机（Perceptron）由两层神经元组成，是一种二分类的线性分类模型，也是最简单的单层前馈神经网络（Feedforward Neural Network）模型。感知机的提出受到生物神经元的启发，神经元在处理突触传递而来的电信号后，若产生的刺激大于一定的阈值，则神经元被激活，感知机也具有类似的结构。假设输入空间是χ⊆R^n，输出空间是y={+1,-1}，x和y分别属于两个空间，则由感知机表示的由输入空间到输出空间的函数为：<br>$$ f(x)=sign(w∙x+b) $$<br>&emsp;&emsp;其中w和b是感知机模型的参数，w∈R^n称为权重(Weight)，b∈R^n称为偏置(Bias)，w∙x表示两个向量间的内积。<br>&emsp;&emsp;Minsky和Papert已证明若决策区域类型是线性可分的，则感知机一定会学习到收敛的参数权重w和偏置b，否则感知机会发生震荡[3]（fluctuation）。因此，感知机在线性可分数据中表现良好，如果设定足够的迭代次数，能很好的处理近似线性可分的数据。但如果对非线性可分的数据，如异或问题，单层感知机不能有效的解决。由于不能用一条直线划分样本空间，有学者想到用多条直线来划分样本，多层感知机就是这样一个模型。多层感知机结构如图1所示，相比较于单层感知机，多层感知机增加了隐藏层的层数。</p><p><center><img src="http://p7jiixmp8.bkt.clouddn.com/image/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E7%BB%93%E6%9E%84%E4%B8%8E%E7%9B%B8%E5%85%B3%E7%AE%97%E6%B3%95/%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA%E7%BB%93%E6%9E%84%E5%9B%BE.jpg?imageMogr2/thumbnail/!70p" alt="多层感知机结构图"></center></p><p><div align="center">图1 多层感知机结构图</div><br>&emsp;&emsp;随着隐藏层数的增加，感知机的分类能力如表1所示。</p><p><div align="center">表1 感知机分类能力比较</div></p><p><center><img src="http://p7jiixmp8.bkt.clouddn.com/image/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E7%BB%93%E6%9E%84%E4%B8%8E%E7%9B%B8%E5%85%B3%E7%AE%97%E6%B3%95/%E6%84%9F%E7%9F%A5%E6%9C%BA%E5%88%86%E7%B1%BB%E8%83%BD%E5%8A%9B%E6%AF%94%E8%BE%832.png" alt="enter image description here"></center><br>&emsp;&emsp;由表可知，在异或问题中，无隐层的感知机不能解决异或问题，引入了隐层后，异或问题得到解决，而随着层数越多，对于异或问题的拟合会越来越好。这说明，在感知机中随着隐藏层层数的增多，决策区域可以拟合任意的区域，因此理论上多层感知机可以解决任何线性或非线性的分类问题。但是，Minsky和Papert提出隐藏层的权重和偏置参数无法训练，这是由于隐藏层不存在期望的输出，无法通过单层感知机的训练方式训练多层感知机[4]。</p><h3 id="反向传播算法"><a href="#反向传播算法" class="headerlink" title="反向传播算法"></a>反向传播算法</h3><p>&emsp;&emsp;如何训练多层感知机的难点在很长一段时间没有得到解决，要训练多层网络，需要更有效的学习算法。反向传播（BackPropagation，BP）算法[1]是训练多层网络的常用方法，该方法用链式法则对网络中所有权重和偏置计算损失函数的梯度，将梯度反馈给随机梯度下降或其它最优化算法，用来更新权值以最小化损失函数。在网络中，正向传播和反向传播的过程如图2所示。在这个例子中输入图片经过网络正向传播后得到的分类是狗，与实际类别的人脸不符，此时会将误差逐层反向传播，修正各个层的权重和偏置参数后，再进行正向传播，反复迭代，直至网络的参数能正确的分类输入的图片。</p><p><center><img src="http://p7jiixmp8.bkt.clouddn.com/image/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E7%BB%93%E6%9E%84%E4%B8%8E%E7%9B%B8%E5%85%B3%E7%AE%97%E6%B3%95/BP%E7%BD%91%E7%BB%9C%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B.jpg" alt="enter image description here"></center></p><p><div align="center">图2 BP网络训练过程</div><br>&emsp;&emsp;反向传播算法的主要步骤如下：</p><ul><li>随机初始化多层网络的权重和偏置参数，将训练数据送入多层网络的输入层，经过隐藏层和输出层，得到输出结果。完成网络的前向传播过程；</li><li>计算输出层实际值和输出值间的偏差，根据反向传播算法中的链式法则，得到每个隐藏层的误差，根据每层的误差调整各层的参数。完成网络的反向传播过程；</li><li>不断迭代前两步中的正向传播和反向传播过程，直至网络收敛。</li></ul><p>&emsp;&emsp;由于还不熟悉markdown的公式编辑，这里省去反向传播的推导过程，感兴趣的朋友可以阅读周志华教授的《机器学习》<code>第五章神经网络</code>里面有详尽的推导过程。</p><h2 id="卷积神经网络的基本思想"><a href="#卷积神经网络的基本思想" class="headerlink" title="卷积神经网络的基本思想"></a>卷积神经网络的基本思想</h2><p>&emsp;&emsp;在BP神经网络中，每一层都是全连接的，参数数量随着网络宽度和深度增加会指数级增长。多层网络结合BP算法对输入数据虽然有强大的表示能力，但巨大的参数一方面限制了每层能够容纳的最大神经元数量，另一方面也限制了神经网络的深度。受到动物视觉皮层中感受野的启发，效仿这种结构的卷积神经网络具有局部连接和参数共享的特点，可以有效的减少网络的相关参数数量，优化网络的训练速度。</p><h3 id="局部连接"><a href="#局部连接" class="headerlink" title="局部连接"></a>局部连接</h3><p>&emsp;&emsp;Hubel和Wiesel在二十世纪五十年代和六十年代的研究表明，猫和猴子的视觉皮层中的神经元只响应特定的某些区域的刺激。将这种视觉刺激影响单个神经元反应的区域称为感受野（receptive field），相邻神经元细胞具有相同或相似的感受野[5]。正是由于发现了感受野等功能在猫的视觉神经中枢中的作用，催生了日本学者福岛邦彦提出带卷积和下采样层的多层卷积神经网络[6-8]。<br>&emsp;&emsp;当我们在处理一副图像时，其输入往往是高维的。传统的神经网络将下一层神经元连接到上一层所有神经元。这种方式随着网络层数的增加，参数数量会爆炸式增加，在实际运用中，会无法训练网络。卷积神经网络中采取的做法是将每个神经元连接到上一层的部分神经元。这种连接的空间范围是一个超参数，称为神经元的感受野，感受野实际上是神经元映射到输入图像矩阵空间的大小。<br>&emsp;&emsp;局部连接的实现方式是引入卷积层，通过卷积层对应局部的图像，每一层的神经元组合在一起对应图像的全局信息。如图3所示，在网络的第m层，每个神经元感受野大小为3，能连接到上一层的3个神经元。m+1层与m层类似。随着层数增加，神经元相对于输入层的感受野会越来越大。每个神经元不会响应感受野以外神经元的变化。受启发于动物的视觉神经元只响应局部信息，这样的结构确保了卷积神经网络只响应上一层局部神经元的变化，起到过滤作用的同时，减少了网络参数。而且随着层数的增加，这种过滤作用会越来越全局。</p><p><center><img src="http://p7jiixmp8.bkt.clouddn.com/image/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E7%BB%93%E6%9E%84%E4%B8%8E%E7%9B%B8%E5%85%B3%E7%AE%97%E6%B3%95/%E5%B1%80%E9%83%A8%E8%BF%9E%E6%8E%A5.png?imageMogr2/thumbnail/!50p" alt="局部连接"></center></p><p><div align="center">图3 局部连接</div></p><h3 id="权值共享"><a href="#权值共享" class="headerlink" title="权值共享"></a>权值共享</h3><p>&emsp;&emsp;卷积的优点除了局部连接外还有权值共享。如图4所示，假设第m-1层有5个神经元，m层有3个神经元，对第m-1层的特征进行卷积，得到第m层共有3个单元的输出特征图。虽然第m层每个神经元都与第m-1层中的3个神经元连接，但同一组卷积操作的权重参数相同。在这个例子中，通过权值共享，将9个参数较少到了3个。</p><p><center><img src="http://p7jiixmp8.bkt.clouddn.com/image/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E7%BB%93%E6%9E%84%E4%B8%8E%E7%9B%B8%E5%85%B3%E7%AE%97%E6%B3%95/%E6%9D%83%E5%80%BC%E5%85%B1%E4%BA%AB.png?imageMogr2/thumbnail/!70p" alt="权值共享"></center></p><p><div align="center">图4 权值共享</div><br>&emsp;&emsp;卷积神经网络中权值共享的实现方式是让同一个卷积核去卷积整张图像，生成一整张特征图[9]。在卷积操作中，同一个卷积核内，所有神经元共享相同权值，权值共享的策略可以很大程度上降低网络需要计算的参数数量。通过权值共享，不仅大大增加了参数的训练效率，而且提取的特征在一定程度上具有位置不变性，加强了特征对输入图像的表达能力。</p><h2 id="卷积神经网络结构"><a href="#卷积神经网络结构" class="headerlink" title="卷积神经网络结构"></a>卷积神经网络结构</h2><p>&emsp;&emsp;卷积神经网络是一种层次模型（Hierarchical Model），其输入是RGB图像，视频，音频等数据。卷积神经网络通过一系列卷积（Convolution）操作，非线性激活函数（Non-linear Activation Function），池化（Pooling）操作层层堆叠，逐层从原始数据获取高层语义信息[10]。<br>如图5所示，在结构上，卷积神经网络分类器有四种类型的网络层：卷积层、池化层、全连接层和分类器。各层次之间的有如下约束：<br>（1）多个卷积（C）和池化（S）层，将上一层的输出图像与本层权重W做卷积得到各个C层，然后经过下采样得到S层。<br>（2）全连接层：全连接层的输入是最后一个卷积池化层的输出，其输出是一个N维的列向量，维度对应类别的个数。<br>（3）分类器：p_1，p_2，p_n的具体数值代表输入图像属于各类别的概率，分类器根据提取到的特征向量将检测目标划分到合适的类中。</p><p><center><img src="http://p7jiixmp8.bkt.clouddn.com/image/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E7%BB%93%E6%9E%84%E4%B8%8E%E7%9B%B8%E5%85%B3%E7%AE%97%E6%B3%95/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%88%86%E7%B1%BB%E5%99%A8.png" alt="卷积神经网络分类器"></center></p><p><div align="center">图5 卷积神经网络分类器</div></p><h3 id="卷积"><a href="#卷积" class="headerlink" title="卷积"></a>卷积</h3><p>&emsp;&emsp;图片有着固有的特性，这意味着，图像的一部分特征与其他部分相似，对一张图片学习到的一部分特征可以用于其他部分。卷积操作受启发于这种特性，具体操作如图6所示，输入图片大小为5×5，经过卷积核大小为3×3的卷积后，原来的输入空间映射到3×3的区域。再经过一次相同大小的卷积核后，图片大小变为了1×1。可见，卷积层逐层提取特征的方式，能从庞大的像素矩阵中，提取到对图像更有代表性的特征。卷积层最重要的是卷积核的设计，卷积核有几个参数:大小、步长、数目、边界填充。这些参数会对卷积的效果带来很大的影响。若卷积核设计的较大，如AlexNet[11]中使用的11×11和5×5的卷积核，其感受野很大，能覆盖图像更大的区域，对图像的“抽象”能力会较好，但较大的卷积核也会带来参数过多的负面影响。卷积核的步长指卷积每次滑动的距离，在一定程度上影响了特征提取的好坏。每一层网络的多个卷积核保证了提取到的特征是图像的多个方面，但卷积核的数量也不是越多越好，过多的卷积核会增加参数数量，计算复杂的同时容易过拟合。边界填充可用于卷积核与图像尺寸不匹配时，填充图像缺失区域。</p><p><center><img src="http://p7jiixmp8.bkt.clouddn.com/image/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E7%BB%93%E6%9E%84%E4%B8%8E%E7%9B%B8%E5%85%B3%E7%AE%97%E6%B3%95/%E5%8D%B7%E7%A7%AF.png" alt="卷积示意图"></center></p><p><div align="center">图6 卷积示意图</div></p><h3 id="池化"><a href="#池化" class="headerlink" title="池化"></a>池化</h3><p>&emsp;&emsp;卷积后的特征依然十分巨大，不仅带来计算性能的下降，也会产生过拟合。于是产生了对一块区域特征进行聚合统计的想法.例如，可以计算图像在某一块区域内的最大值或平均值代替这一块区域的特征，在降低特征维度的同时能使提取到的特征更具有代表性，还会使得处理过后的特征图谱拥有更大的感受野，这种用部分特征代替整体特征的操作称为池化[10]（Pooling）。常用的池化方法如下：最大值池化（Max Pooling）；均值池化（Mean Pooling）；随机池化（Random Pooling）。池化操作具有以下优良特性：<br>（1）平移不变性（Translation Invariant）。无论是哪种池化方式，提取的都是局部特征。池化操作会模糊特征的具体位置，图像发生了平移后，依然能产生相同的特征。<br>（2）特征降维（Feature Dimension Reduction），池化操作将一个局部区域的特征进一步抽象，池化中的一个元素对应输入数据中的一个区域，可以减少参数数量，降低维度。<br>&emsp;&emsp;池化操作的功能是减小特征空间的大小，以减小网络中的参数和计算量，从而避免过度拟合。如图7所示，224×224×64经过大小为2×2，步长为2的池化核，变成了112×112×64，使得特征图谱减少为原来的1/2。图7中池化方式是最大池化，即将一个区域内的最大值表示为这个区域的池化结果。</p><p><center><img src="http://p7jiixmp8.bkt.clouddn.com/image/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E7%BB%93%E6%9E%84%E4%B8%8E%E7%9B%B8%E5%85%B3%E7%AE%97%E6%B3%95/%E6%B1%A0%E5%8C%96%E7%A4%BA%E6%84%8F%E5%9B%BE.png" alt="池化示意图"></center></p><p><div align="center">图7 池化示意图</div></p><h3 id="全连接层"><a href="#全连接层" class="headerlink" title="全连接层"></a>全连接层</h3><p>&emsp;&emsp;前面讨论的卷积层，池化层等操作是将原始数据映射到特征空间，使得到的特征矩阵越来越抽象并对特征有良好的表达能力。Softmax分类器要求输入是列向量，需要全连接层将卷积和池化的输出映射到线性可分空间。<br>全连接层可以聚合卷积和池化操作得到的高阶特征，并且可以简化参数模型，一定程度的减少神经元数量和训练参数。为了能用反向传播算法训练网络，全连接层要求图片有固定的输入尺寸。因此早期网络中，需要对不同尺寸的图片进行裁剪或拉伸，这种操作会带来图片信息的失真和损失。在第三章讨论的感兴趣（Region of Interest）池化方法，可以很好的解决这一问题。<br>&emsp;&emsp;卷积层是由全连接层发展而来，全连接层可以用特殊的卷积层表示，对于前一层全连接的全连接层可以用卷积核大小为1×1的卷积层替代，而对于前一层是卷积的全连接层可以用对上一层所有输入全局卷积的卷积层替代。在全连接层中可以认为每个神经元的感受野是整个图像。全连接层隐藏层节点数越多，模型拟合能力越强，但参数冗余会带来过拟合的风险而且会降低效率。对于这个问题，一般的做法是采用正则化（Regularization）技术，如L1、L2范式。还有通过Dropout随机舍弃一些神经元，来减少权重连接，然后增强网络模型在缺失个体连接信息情况下的鲁棒性[10]。</p><h3 id="分类器"><a href="#分类器" class="headerlink" title="分类器"></a>分类器</h3><p>&emsp;&emsp;经过全连接层将特征映射到线性空间后，最后还需要将实例数据划分到合适的分类中。分类器有多种，常用的有支持向量机和Softmax回归，此处以Softmax为例子。Softmax函数用于将多个神经元的输出映射到(0,1)之间，转化为概率问题，从而处理多分类问题。如图8所示，Softmax层的输入分别是3、1和-3，在经过Softmax层后分别映射为0.85、0.12和0.03，三个值的累加和为1，其数值可以理解为概率，则属于y_1类的概率最大为0.85。这幅图是Softmax的通俗理解，具体推导过程可以参考<a href="http://ufldl.stanford.edu/wiki/index.php/Softmax%E5%9B%9E%E5%BD%92" target="_blank" rel="noopener">这篇文章</a>。</p><p><center><img src="http://p7jiixmp8.bkt.clouddn.com/image/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E7%BB%93%E6%9E%84%E4%B8%8E%E7%9B%B8%E5%85%B3%E7%AE%97%E6%B3%95/softmax%E5%B1%82.png" alt="Softmax层"></center></p><p><div align="center">图8 Softmax层</div></p><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>[1]    Rumelhart D E, Hinton G E, Williams R J. Learning representations by back-propagating errors [J]. Nature, 1986, 323(6088): 533-536.<br>[2]    Hinton G E, Osindero S, Teh Y W. A fast learning algorithm for deep belief nets [J]. Neural Computation, 2006, 18(7): 1527-1554.<br>[3]    Minsky M, Papert S. Perceptrons: An introduction to computational geometry [J]. 1969, 75(3): 3356-3362.<br>[4]    Minsky M L, Papert S A. Perceptrons (expanded edition) mit press [J]. 1988.<br>[5]    刘建立, 沈菁, 王蕾, 等. 织物纹理的简单视神经细胞感受野的选择特性 [J]. 计算机工程与应用, 2014, 50(1): 185-190.<br>[6]    Fukushima K. Neocognitron: A self-organizing neural network model for a mechanism of pattern recognition unaffected by shift in position [J]. Biological Cybernetics, 1980, 36(4): 193-202.<br>[7]    Fukushima K. Neocognitron: A hierarchical neural network capable of visual pattern recognition [J]. Neural Networks, 1988, 1(2): 119-130.<br>[8]    Fukushima K, Miyake S. Neocognitron: A new algorithm for pattern recognition tolerant of deformations and shifts in position [J]. Pattern Recognition, 1982, 15(6): 455-469.<br>[9]    曹婷. 一种基于改进卷积神经网络的目标识别方法研究 [D]. 湖南大学, 2016.<br>[10]    LeCun Y, Boser B, Denker J S, et al. Backpropagation applied to handwritten zip code recognition [J]. Neural computation, 1989, 1(4): 541-551.<br>[11]    Krizhevsky A, Sutskever I, Hinton G E. Imagenet classification with deep convolutional neural networks [C]. Proceedings of 26th Annual Conference on Neural Information Processing Systems, Nevada:NIPS, 2012: 1097-1105.</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;引言&quot;&gt;&lt;a href=&quot;#引言&quot; class=&quot;headerlink&quot; title=&quot;引言&quot;&gt;&lt;/a&gt;引言&lt;/h2&gt;&lt;p&gt;&amp;emsp;&amp;emsp;早在上世纪50年代，美国神经生物学家David Hubel通过研究猫和猴子的瞳孔区域与大脑皮层神经元的对应关系就发现视觉系统的信息处理方式是分级的。这一发现，促成了神经网络在图像处理上的发展。
    
    </summary>
    
      <category term="深度学习笔记" scheme="https://oysz2016.github.io/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="深度学习" scheme="https://oysz2016.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="BP算法" scheme="https://oysz2016.github.io/tags/BP%E7%AE%97%E6%B3%95/"/>
    
      <category term="感知机" scheme="https://oysz2016.github.io/tags/%E6%84%9F%E7%9F%A5%E6%9C%BA/"/>
    
      <category term="卷积" scheme="https://oysz2016.github.io/tags/%E5%8D%B7%E7%A7%AF/"/>
    
      <category term="池化" scheme="https://oysz2016.github.io/tags/%E6%B1%A0%E5%8C%96/"/>
    
      <category term="全连接" scheme="https://oysz2016.github.io/tags/%E5%85%A8%E8%BF%9E%E6%8E%A5/"/>
    
      <category term="卷积神经网络" scheme="https://oysz2016.github.io/tags/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>什么是深度学习</title>
    <link href="https://oysz2016.github.io/2018/04/24/%E4%BB%80%E4%B9%88%E6%98%AF%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    <id>https://oysz2016.github.io/2018/04/24/什么是深度学习/</id>
    <published>2018-04-24T07:53:22.592Z</published>
    <updated>2018-04-24T08:36:14.726Z</updated>
    
    <content type="html"><![CDATA[<h2 id="机器学习"><a href="#机器学习" class="headerlink" title="机器学习"></a>机器学习</h2><p>&emsp;&emsp;比起深度学习，“机器学习”一词更耳熟能详。机器学习是人工智能的一个分支，它致力于研究如何通过计算的手段，利用经验来改善计算机系统自身的性能。通过从经验中获取知识，机器学习算法摒弃了人为向机器输入知识的操作，转而凭借算法自身来学到所需所有知识。对于传统机器学习算法而言，“经验”往往对应以“特征”形式存储的“数据”，传统机器学习算法所做的事情便是依靠这些数据产生“模型”。<a id="more"></a><br>&emsp;&emsp;特征的意义是找一个更好的空间去重构表达数据，把原始数据映射到高维空间，更便于划分不同类的数据。特征的选取是机器学习的核心，通常线性可分的数据用最简单的感知机即可划分，而现实应用中的数据往往是高维复杂的，传统的特征提取的方式可以归纳为以下几种：</p><ul><li><strong>依据经验人工挑选</strong>：如关于天气的数据集，如果是预测是否下雨，可以挑选与降雨密切相关的特征：季节、紫外线指数、温度、湿度、是否有云、风向和风速等属性。</li><li><strong>线性特征选择</strong>：假设特征之间相互独立，不存在交互，那么可以使用卡方检验、信息增益、互信息等方法逐个检验特征与结果之间的相关程度。更为简便的方法是使用LR等线性模型，先做一次预训练，根据特征对应的线性模型权值的绝对值大小来对特征的重要程度进行排序。</li><li><strong>非线性特征选择</strong>：如果属性之间不是相互独立，可以使用随机森林来进行特征选择，概括来说就是将想要检验重要性的特征在样本上进行permutation，然后观察OOB错误的上升程度，上升越大，说明这个特征越重要。</li></ul><p>&emsp;&emsp;以上介绍的都是传统的特征提取方式，而随着机器学习任务的复杂多变，现有的特征提取方法表现出了诸多弊端，针对一个数据集设计特征提取方法不仅费时费力，而且还十分敏感，换成其他的任务，表现往往不尽人意。得益于计算机硬件的发展和大数据时代的到来，计算机拥有了能处理大量数据的前提和能力，促进了深度学习的发展。</p><h2 id="深度学习的实质"><a href="#深度学习的实质" class="headerlink" title="深度学习的实质"></a>深度学习的实质</h2><p>&emsp;&emsp;深度学习以原始数据作为输入，经过算法层层的将数据抽象为自身任务所需要的最终特征表示。通过大量的数据逐层学习特征，免去了传统特征提取过程中人类先验知识的影响。通过数据自主的学习特征，以获取输入信息更本质的特征[1, 2]。<br>&emsp;&emsp;深度学习的实质，是通过构建具有很多隐层的机器学习模型和海量的训练数据，来学习更有用的特征，从而最终提升分类或预测的准确性。因此，“深度模型”是手段，“特征学习”是目的。区别于传统的浅层学习，深度学习的不同在于：</p><ul><li><strong>强调了模型结构的深度</strong>，通常有5层、6层，甚至10多层的隐层节点；</li><li><strong>明确突出了特征学习的重要性</strong>，也就是说，通过逐层特征变换，将样本在原空间的特征表示变换到一个新特征空间，从而使分类或预测更加容易。</li><li>与人工规则构造特征的方法相比，<strong>利用大数据来学习特征</strong>，更能够刻画数据的丰富内在信息。</li></ul><h2 id="深度学习的网络模型"><a href="#深度学习的网络模型" class="headerlink" title="深度学习的网络模型"></a>深度学习的网络模型</h2><p>&emsp;&emsp;相比较于传统的机器学习算法，深度学习除了模型学习，还有特征学习、特征抽象等任务模块的参与，借助多层任务模块完成最终学习任务，故称为“深度”学习。深度学习发展到如今已经有了多种结构的深度神经网络模型，如：</p><ul><li>由多个受限玻尔兹曼机组成的<strong>深度信念网络（Deep Belief Network，DBN）</strong>[3];</li><li>应用于自然语言处理的<strong>循环神经网络（Recurrent Neural Network，RNN）</strong>[4];</li><li>具有局部连接和权值共享等优点的<strong>卷积神经网络（Convolutional Neural Network，CNN）</strong>[5]。<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2>[1] Bottou L, Chapelle O, Decoste D, et al. Scaling learning algorithms towards AI[J]. Large-scale kernel machines,2007,34(5): 321-359.<br>[2] Bengio Y, Delalleau O. On the expressive power of deep architectures [C]. Proceedings of International Conference on Algorithmic Learning Theory, Springer-Verlag, 2011: 18-36.<br>[3] Mikolov T, Karafiát M, Burget L, et al. Recurrent neural network based language model [C]. Proceedings of 11th Annual Conference of the International Speech Communication Association, Chiba: Interspeech, 2010: 1045-1048.<br>[4] LeCun Y, Boser B, Denker J S, et al. Backpropagation applied to handwritten zip code recognition [J]. Neural computation, 1989, 1(4): 541-551.</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;机器学习&quot;&gt;&lt;a href=&quot;#机器学习&quot; class=&quot;headerlink&quot; title=&quot;机器学习&quot;&gt;&lt;/a&gt;机器学习&lt;/h2&gt;&lt;p&gt;&amp;emsp;&amp;emsp;比起深度学习，“机器学习”一词更耳熟能详。机器学习是人工智能的一个分支，它致力于研究如何通过计算的手段，利用经验来改善计算机系统自身的性能。通过从经验中获取知识，机器学习算法摒弃了人为向机器输入知识的操作，转而凭借算法自身来学到所需所有知识。对于传统机器学习算法而言，“经验”往往对应以“特征”形式存储的“数据”，传统机器学习算法所做的事情便是依靠这些数据产生“模型”。
    
    </summary>
    
      <category term="深度学习笔记" scheme="https://oysz2016.github.io/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="机器学习" scheme="https://oysz2016.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="深度学习" scheme="https://oysz2016.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="特征提取" scheme="https://oysz2016.github.io/tags/%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96/"/>
    
  </entry>
  
  <entry>
    <title>基于Github和Hexo的个人博客搭建</title>
    <link href="https://oysz2016.github.io/2018/04/23/%E5%9F%BA%E4%BA%8EGithub%E5%92%8CHexo%E7%9A%84%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/"/>
    <id>https://oysz2016.github.io/2018/04/23/基于Github和Hexo的个人博客搭建/</id>
    <published>2018-04-23T06:58:31.854Z</published>
    <updated>2018-04-24T08:39:41.026Z</updated>
    
    <content type="html"><![CDATA[<h2 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h2><p>&emsp;&emsp;去年起看了很多大牛的博客，也萌生了搭建个人博客的想法，为什么搭建博客，总结下来有以下好处：</p><ul><li><strong>书写是为了更好的思考</strong></li><li><strong>激励自己持续学习</strong></li><li><strong>尝试持之以恒的去做一些事情</strong><a id="more"></a></li></ul><p>&emsp;&emsp;这次趁着大论文盲审结果还没出来和导师还没反馈小论文修改意见的间隙，花了一个周末的时间搭建好了自己的个人博客。在此将搭建过程作为自己的第一篇博客记录下来。</p><h2 id="Hexo简介"><a href="#Hexo简介" class="headerlink" title="Hexo简介"></a>Hexo简介</h2><p><img src="http://p7jiixmp8.bkt.clouddn.com/1524460444%281%29.jpg" alt="enter image description here"><br>&emsp;&emsp;Hexo 是一个基于 Node.js 的静态博客程序，可以方便的生成静态网页托管在github和Heroku上。Hexo有着丰富的主题，可以定制多种样式。<br>hexo特性：</p><ul><li>速度快：Hexo基于Node.js，支持多进程，几百篇文章也可以秒生成；</li><li>撰写工具丰富：支持GitHub Flavored Markdown和所有Octopress的插件；</li><li>扩展性强： Hexo支持EJS、Swig和Stylus。通过插件支持Haml、Jade和Less。</li></ul><p>&emsp;&emsp;使用hexo时，有以下常用命令：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">npm install hexo -g #安装</span><br><span class="line">npm install hexo -g #安装  </span><br><span class="line">npm update hexo -g #升级  </span><br><span class="line">hexo init #初始化</span><br><span class="line">hexo n &quot;我的博客&quot; == hexo new &quot;我的博客&quot; #新建文章</span><br><span class="line">hexo p == hexo publish</span><br><span class="line">hexo g == hexo generate#生成</span><br><span class="line">hexo s == hexo server #启动服务预览</span><br><span class="line">hexo d == hexo deploy#部署</span><br><span class="line">hexo new 创建文章</span><br></pre></td></tr></table></figure></p><h2 id="环境搭建-node-hexo-git"><a href="#环境搭建-node-hexo-git" class="headerlink" title="环境搭建(node,hexo,git)"></a>环境搭建(node,hexo,git)</h2><p>&emsp;&emsp;前面说过hexo是基于node.js，因此需要先安装<a href="https://nodejs.org/en/" target="_blank" rel="noopener">node.js</a>。git的配置这里就不再赘述，可以参考廖雪峰老师的<a href="https://www.liaoxuefeng.com/wiki/0013739516305929606dd18361248578c67b8067c8c017b000/" target="_blank" rel="noopener">Git教程</a>。安装好Git后，需要将其与自己的GitHub账号关联上。安装好node.js后，仅需一步即可安装hexo的相关套件。在命令行输入:</p><pre><code>npm install hexo -g hexo-cli</code></pre><p>&emsp;&emsp;到这一步就安装好了所需的所用环境。</p><h2 id="设置"><a href="#设置" class="headerlink" title="设置"></a>设置</h2><p>&emsp;&emsp;在搭建自己的博客前，需要设置一个博客的根目录。使用命令行切换到该根目录下，输入：</p><pre><code>hexo init blog</code></pre><p>&emsp;&emsp;等待片刻，成功后会提示<code>INFO  Start blogging with Hexo!</code>初始化成功后，目录如下：</p><pre><code>.├── _config.yml├── package.json├── scaffolds├── source|   ├── _drafts|   └── _posts└── themes</code></pre><p>&emsp;&emsp;source的_posts目录下会自带一篇题为“Hello World”的示例文章，直接执行以下操作可以看到网站初步的模样:</p><pre><code>$ hexo generate# 启动本地服务器$ hexo server# 在浏览器输入 http://localhost:4000/就可以看见网页和模板了,若端口号被占用，可输入hexo server -p 4001改为其他端口号。</code></pre><p>&emsp;&emsp;访问<a href="http://localhost:4000/，界面如下：" target="_blank" rel="noopener">http://localhost:4000/，界面如下：</a><br><img src="http://p7jiixmp8.bkt.clouddn.com/%E5%8D%9A%E5%AE%A2%E5%88%9D%E5%A7%8B%E8%A7%86%E5%9B%BE.png" alt="enter image description here"></p><h2 id="部署及配置博客"><a href="#部署及配置博客" class="headerlink" title="部署及配置博客"></a>部署及配置博客</h2><h3 id="配置SSH"><a href="#配置SSH" class="headerlink" title="配置SSH"></a>配置SSH</h3><p>&emsp;&emsp;在上一步看到了网站的默认效果，此时需要将该博客部署到Github上，登陆Github，创建名为your_name.github.io(your_name替换成你的用户名)的仓库。重新打开CMD,输入：</p><pre><code>ssh-keygen -t rsa -C &quot;Github的注册邮箱地址&quot;</code></pre><p>&emsp;&emsp;一路Enter，得到信息：<code>Your public key has been saved in /c/Users/user/.ssh/id_rsa.pub.</code>根据保存的路径找到id_rsa.pub文件，用编辑器打开，复制所有内容，然后<a href="https://github.com/login?return_to=https://github.com/settings/ssh" target="_blank" rel="noopener">Sign in to GitHub</a>，按以下步骤配置SSH：<br>&emsp;&emsp;New SSH key ——&gt;Title：blog ——&gt; Key：输入刚才复制的—— &gt;Add SSH key</p><h3 id="配置博客"><a href="#配置博客" class="headerlink" title="配置博客"></a>配置博客</h3><p>&emsp;&emsp;在blog目录下，用编辑器打开_config.yml，修改其中的配置信息。<br>&emsp;&emsp;修改网站中的相关信息 ：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">title: #标题</span><br><span class="line">subtitle: #副标题</span><br><span class="line">description: #站点描述</span><br><span class="line">author: #作者</span><br><span class="line">language: zh-Hans</span><br><span class="line">email:  #电子邮箱</span><br><span class="line">timezone: Asia/Shanghai</span><br></pre></td></tr></table></figure></p><p>&emsp;&emsp;配置部署仓库</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">deploy: </span><br><span class="line">  type: git</span><br><span class="line">  repo: 刚刚github创库地址.git</span><br><span class="line">  branch: master</span><br></pre></td></tr></table></figure><p>&emsp;&emsp;特别提醒，在每个参数的：后都要加一个空格。以上操作完成后，执行：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">hexo clean #清除缓存 网页正常情况下可以忽略此条命令</span><br><span class="line">hexo generate #生成</span><br><span class="line">hexo server #启动服务预览，非必要，可本地浏览网页</span><br><span class="line">hexo deploy #部署发布</span><br></pre></td></tr></table></figure><p>&emsp;&emsp;得到提示信息<code>INFO  Deploy done: git</code>表示成功发布到Github上。然后在浏览器里输入your_name.github.io就可以访问刚刚配置好的博客了。</p><h2 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h2><p>&emsp;&emsp;到此为止，最基本的hexo+github搭建博客完结。hexo有许多优美简洁的主题，网上也有许多关于主题美化的教程，可以根据自己的喜好添加各种或实用或酷炫的功能。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;写在前面&quot;&gt;&lt;a href=&quot;#写在前面&quot; class=&quot;headerlink&quot; title=&quot;写在前面&quot;&gt;&lt;/a&gt;写在前面&lt;/h2&gt;&lt;p&gt;&amp;emsp;&amp;emsp;去年起看了很多大牛的博客，也萌生了搭建个人博客的想法，为什么搭建博客，总结下来有以下好处：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;书写是为了更好的思考&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;激励自己持续学习&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;尝试持之以恒的去做一些事情&lt;/strong&gt;
    
    </summary>
    
      <category term="Hexo博客搭建教程" scheme="https://oysz2016.github.io/categories/Hexo%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E6%95%99%E7%A8%8B/"/>
    
    
      <category term="hexo" scheme="https://oysz2016.github.io/tags/hexo/"/>
    
  </entry>
  
</feed>
